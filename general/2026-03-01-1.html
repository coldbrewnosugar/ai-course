<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Vectorless RAG with PageIndex: Ditch the Vector DB — Tinker</title>
  <style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fraunces:ital,opsz,wght@0,9..144,400;0,9..144,600;0,9..144,700;0,9..144,800;1,9..144,400&family=IBM+Plex+Mono:wght@400;500;600&display=swap');
:root {
  --bg: #FAFAFA;
  --bg-subtle: #F4F4F5;
  --bg-elevated: #FFFFFF;
  --ink: #18181B;
  --ink-secondary: #52525B;
  --muted: #A1A1AA;
  --accent: #E5484D;
  --accent-hover: #CD2B31;
  --accent-light: rgba(229,72,77,0.06);
  --accent-subtle: rgba(229,72,77,0.12);
  --blue: #3B82F6;
  --red: #EF4444;
  --yellow: #EAB308;
  --green: #22C55E;
  --surface: #F4F4F5;
  --border: #E4E4E7;
  --border-subtle: #F4F4F5;
  --shadow-sm: 0 1px 2px rgba(0,0,0,0.04);
  --shadow-md: 0 2px 8px rgba(0,0,0,0.06), 0 0 0 1px rgba(0,0,0,0.03);
  --shadow-lg: 0 4px 16px rgba(0,0,0,0.08), 0 0 0 1px rgba(0,0,0,0.02);
  --mono: 'IBM Plex Mono', monospace;
  --display: 'Fraunces', Georgia, serif;
  --sans: 'Inter', -apple-system, system-ui, sans-serif;
  --max-w: 680px;
  --max-w-wide: 780px;
  --radius-sm: 4px;
  --radius-md: 8px;
  --radius-lg: 12px;
}
*, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }
body {
  font-family: var(--sans);
  background: var(--bg);
  color: var(--ink);
  min-height: 100vh;
  -webkit-font-smoothing: antialiased;
  line-height: 1.7;
  font-size: 17px;
  border-top: 3px solid var(--accent);
}

/* ── Track color worlds ── */
body.track-general { /* default coral — uses :root values */ }
body.track-image-gen { --accent: #8B5CF6; --accent-hover: #7C3AED; --accent-light: rgba(139,92,246,0.06); --accent-subtle: rgba(139,92,246,0.12); }
body.track-audio { --accent: #F59E0B; --accent-hover: #D97706; --accent-light: rgba(245,158,11,0.06); --accent-subtle: rgba(245,158,11,0.12); }

/* ── Layout ── */
.session-container {
  max-width: var(--max-w);
  margin: 0 auto;
  padding: 0 1.5rem 5rem;
}

/* ── Back link ── */
.back-link {
  display: inline-flex;
  align-items: center;
  gap: 0.35rem;
  font-family: var(--sans);
  font-size: 0.8rem;
  font-weight: 500;
  color: var(--muted);
  text-decoration: none;
  padding: 2rem 0 1.25rem;
  transition: color 0.15s;
}
.back-link:hover { color: var(--accent); }

/* ── Hero ── */
.session-hero {
  padding: 1rem 0 2.5rem;
  margin-bottom: 2rem;
  border-bottom: 1px solid var(--border);
}
.session-hero .hero-tag {
  display: inline-block;
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 600;
  letter-spacing: 0.06em;
  text-transform: uppercase;
  color: var(--accent);
  background: var(--accent-light);
  padding: 0.3rem 0.75rem;
  margin-bottom: 1.25rem;
  border-radius: var(--radius-sm);
}
.session-hero h1 {
  font-family: var(--display);
  font-size: 2.5rem;
  font-weight: 800;
  line-height: 1.15;
  letter-spacing: -0.025em;
  margin-bottom: 0.6rem;
  font-optical-sizing: auto;
}
.session-hero .hero-subtitle {
  font-size: 1.1rem;
  color: var(--ink-secondary);
  font-weight: 400;
  line-height: 1.5;
}
.session-hero .hero-meta {
  display: flex;
  gap: 1.25rem;
  margin-top: 1.25rem;
  font-family: var(--mono);
  font-size: 0.7rem;
  color: var(--muted);
  letter-spacing: 0.02em;
}
.hero-meta .tag {
  display: inline-block;
  background: var(--surface);
  padding: 0.2rem 0.55rem;
  font-size: 0.65rem;
  border-radius: var(--radius-sm);
  border: 1px solid var(--border);
}

/* ── Section divider ── */
.section-divider {
  border: none;
  width: 32px;
  height: 2px;
  background: var(--accent);
  margin: 3rem 0;
}

/* ── Context block ── */
.context-block {
  background: var(--bg-elevated);
  padding: 1.5rem 1.75rem;
  margin-bottom: 2.5rem;
  border-radius: var(--radius-md);
  border: 1px solid var(--border);
}
.context-block h2 {
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 600;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  color: var(--accent);
  margin-bottom: 0.75rem;
}
.context-block p { margin-bottom: 0.75rem; }
.context-block p:last-child { margin-bottom: 0; }

/* ── Steps ── */
.step-section { margin-bottom: 3rem; }
.step-header {
  display: flex;
  align-items: flex-start;
  gap: 1rem;
  margin-bottom: 1.25rem;
}
.step-number {
  flex-shrink: 0;
  width: 44px; height: 44px;
  background: var(--ink);
  color: #fff;
  font-family: var(--mono);
  font-size: 0.9rem;
  font-weight: 600;
  display: flex;
  align-items: center;
  justify-content: center;
  border-radius: var(--radius-sm);
}
.step-header h2 {
  font-family: var(--display);
  font-size: 1.3rem;
  font-weight: 700;
  line-height: 1.25;
  padding-top: 0.35rem;
}
.step-body p { margin-bottom: 0.75rem; }
.step-body ul, .step-body ol { margin: 0.5rem 0 0.75rem 1.5rem; }
.step-body li { margin-bottom: 0.35rem; }
.step-body strong { font-weight: 600; }
.step-body a { color: var(--accent); text-decoration: underline; text-decoration-color: var(--accent-subtle); text-underline-offset: 2px; }
.step-body a:hover { text-decoration-color: var(--accent); }

/* ── Code blocks ── */
.code-block {
  position: relative;
  margin: 1.25rem 0;
  background: var(--ink);
  border-radius: var(--radius-md);
  overflow: hidden;
}
.code-caption {
  display: block;
  padding: 0.55rem 1rem;
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 500;
  color: rgba(255,255,255,0.4);
  border-bottom: 1px solid rgba(255,255,255,0.08);
  letter-spacing: 0.03em;
}
.code-block pre {
  padding: 1rem;
  overflow-x: auto;
  margin: 0;
  background: transparent;
}
.code-block code {
  font-family: var(--mono);
  font-size: 0.82rem;
  line-height: 1.6;
  color: #E4E4E7;
}
.copy-btn {
  position: absolute;
  top: 0.45rem;
  right: 0.5rem;
  font-family: var(--mono);
  font-size: 0.55rem;
  font-weight: 600;
  letter-spacing: 0.04em;
  text-transform: uppercase;
  background: rgba(255,255,255,0.1);
  color: rgba(255,255,255,0.5);
  border: none;
  padding: 0.25rem 0.55rem;
  cursor: pointer;
  transition: all 0.15s;
  border-radius: var(--radius-sm);
}
.copy-btn:hover { background: rgba(255,255,255,0.2); color: #fff; }
.copy-btn.copied { background: var(--green); color: #fff; }

/* ── Callouts ── */
.callout {
  padding: 1rem 1.25rem;
  margin: 1.25rem 0;
  font-size: 0.92rem;
  border-radius: var(--radius-md);
  border: 1px solid;
  background: var(--bg-elevated);
}
.callout-tip {
  border-color: rgba(59,130,246,0.25);
  background: rgba(59,130,246,0.04);
}
.callout-warning {
  border-color: rgba(239,68,68,0.4);
  background: rgba(239,68,68,0.04);
}
.callout-api-key-note {
  border-color: rgba(234,179,8,0.3);
  background: rgba(234,179,8,0.05);
}
.callout-label {
  font-family: var(--mono);
  font-size: 0.6rem;
  font-weight: 600;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  margin-bottom: 0.35rem;
}
.callout-tip .callout-label { color: var(--blue); }
.callout-warning .callout-label { color: var(--red); }
.callout-api-key-note .callout-label { color: #CA8A04; }

/* ── Reveals (details/summary) ── */
.reveal {
  margin: 1rem 0;
  border-radius: var(--radius-md);
  overflow: hidden;
  border: 1px solid var(--border);
  background: var(--bg-elevated);
}
.reveal summary {
  font-family: var(--sans);
  font-size: 0.85rem;
  font-weight: 600;
  padding: 0.75rem 1rem;
  cursor: pointer;
  background: var(--bg-elevated);
  list-style: none;
  display: flex;
  align-items: center;
  gap: 0.5rem;
  transition: background 0.15s;
}
.reveal summary:hover { background: var(--surface); }
.reveal summary::before {
  content: "+";
  font-family: var(--mono);
  font-size: 0.85rem;
  font-weight: 600;
  color: var(--accent);
}
.reveal[open] summary::before {
  content: "\2212";
}
.reveal .reveal-body {
  padding: 1rem;
  border-top: 1px solid var(--border);
  font-size: 0.92rem;
}
.reveal .reveal-body p { margin-bottom: 0.5rem; }
.reveal .reveal-body p:last-child { margin-bottom: 0; }

/* ── Checkpoint ── */
.checkpoint {
  display: flex;
  align-items: center;
  gap: 0.85rem;
  padding: 0.85rem 1.25rem;
  background: var(--accent-light);
  color: var(--ink);
  margin: 2rem 0;
  font-family: var(--sans);
  font-size: 0.85rem;
  font-weight: 600;
  border-radius: var(--radius-md);
  border: 1px solid var(--accent-subtle);
}
.checkpoint-icon {
  flex-shrink: 0;
  width: 26px; height: 26px;
  background: var(--accent);
  border-radius: var(--radius-sm);
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 0.75rem;
  color: #fff;
}

/* ── Decision point ── */
.decision-point {
  margin: 2rem 0;
  padding: 1.5rem;
  border-radius: var(--radius-md);
  background: var(--bg-elevated);
  border: 1px solid var(--border);
}
.decision-point h3 {
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 600;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  color: var(--accent);
  margin-bottom: 0.5rem;
}
.decision-point .question {
  font-family: var(--display);
  font-size: 1.1rem;
  font-weight: 600;
  margin-bottom: 1rem;
  line-height: 1.35;
}
.decision-option {
  margin-bottom: 0.5rem;
}
.decision-option input[type="radio"] {
  display: none;
}
.decision-option label {
  display: block;
  padding: 0.7rem 1rem;
  background: var(--surface);
  border: 1.5px solid var(--border);
  cursor: pointer;
  transition: all 0.15s;
  font-weight: 500;
  font-size: 0.92rem;
  border-radius: var(--radius-md);
}
.decision-option label:hover {
  background: var(--accent-light);
  border-color: var(--accent);
}
.decision-option input:checked + label {
  border-color: var(--accent);
  background: var(--accent-light);
}
.decision-feedback {
  display: none;
  padding: 0.65rem 0.85rem;
  margin-top: 0.35rem;
  font-size: 0.85rem;
  border-left: 3px solid;
  border-radius: var(--radius-sm);
}
.decision-option input:checked ~ .decision-feedback {
  display: block;
}
.decision-feedback.correct {
  border-color: var(--green);
  background: rgba(34,197,94,0.06);
  color: #15803D;
}
.decision-feedback.incorrect {
  border-color: var(--red);
  background: rgba(239,68,68,0.05);
  color: #DC2626;
}

/* ── Agent interaction ── */
.agent-interaction {
  margin: 1.5rem calc((var(--max-w) - var(--max-w-wide)) / 2);
  border-radius: var(--radius-md);
  overflow: hidden;
  border: 1px solid var(--border);
}
.agent-goal {
  padding: 1rem 1.25rem;
  background: var(--ink);
  color: #E4E4E7;
  font-family: var(--mono);
  font-size: 0.82rem;
  font-weight: 500;
  line-height: 1.5;
}
.agent-goal::before {
  content: none;
}
.agent-goal-label {
  font-size: 0.55rem;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  margin-bottom: 0.4rem;
  display: flex;
  align-items: center;
  gap: 0.4rem;
  color: rgba(255,255,255,0.35);
}
.agent-goal-label::before {
  content: "";
  display: inline-block;
  width: 6px; height: 6px;
  background: var(--green);
  border-radius: 50%;
}
.agent-hints {
  padding: 1rem 1.25rem;
  background: var(--surface);
  border-bottom: 1px solid var(--border);
}
.agent-hints-label {
  font-family: var(--mono);
  font-size: 0.6rem;
  font-weight: 600;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  color: var(--accent);
  margin-bottom: 0.5rem;
}
.agent-hints ul {
  list-style: none;
  padding: 0;
}
.agent-hints li {
  padding: 0.3rem 0 0.3rem 1.25rem;
  position: relative;
  font-size: 0.9rem;
  font-style: italic;
  color: var(--ink-secondary);
}
.agent-hints li::before {
  content: "\203A";
  position: absolute;
  left: 0;
  color: var(--accent);
  font-weight: 700;
  font-style: normal;
  font-family: var(--mono);
}

/* Agent interaction reveals */
.agent-interaction .reveal {
  border-radius: 0;
  border: none;
  border-top: 1px solid var(--border);
}
.agent-interaction .reveal summary {
  font-size: 0.8rem;
  background: var(--surface);
}

/* ── Your turn ── */
.your-turn {
  padding: 1.5rem;
  margin: 2rem 0;
  border-radius: var(--radius-md);
  background: var(--accent-light);
  border: 1.5px solid var(--accent-subtle);
}
.your-turn h3 {
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 600;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  color: var(--accent);
  margin-bottom: 0.5rem;
}
.your-turn .your-turn-goal {
  font-family: var(--sans);
  font-size: 1.05rem;
  font-weight: 600;
  margin-bottom: 0.75rem;
  line-height: 1.4;
}
.your-turn .your-turn-context {
  font-size: 0.92rem;
  color: var(--ink-secondary);
  margin-bottom: 1rem;
}

/* ── Recap ── */
.recap-section {
  padding-top: 2.5rem;
  margin-top: 3rem;
  border-top: 1px solid var(--border);
}
.recap-section h2 {
  font-family: var(--display);
  font-size: 1.35rem;
  font-weight: 700;
  margin-bottom: 1rem;
}
.recap-body { margin-bottom: 1.5rem; }
.recap-body p { margin-bottom: 0.75rem; }
.takeaways-list {
  list-style: none;
  padding: 0;
  margin-bottom: 1.5rem;
}
.takeaways-list li {
  padding: 0.55rem 0 0.55rem 1.75rem;
  position: relative;
  font-size: 0.95rem;
}
.takeaways-list li::before {
  content: "\2713";
  position: absolute;
  left: 0;
  color: var(--green);
  font-weight: 700;
  font-size: 0.85rem;
}
.next-steps h3 {
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 600;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  color: var(--muted);
  margin-bottom: 0.5rem;
}
.next-steps ul {
  list-style: none;
  padding: 0;
}
.next-steps li {
  padding: 0.3rem 0 0.3rem 1.5rem;
  position: relative;
}
.next-steps li::before {
  content: "\2192";
  position: absolute;
  left: 0;
  color: var(--accent);
  font-weight: 700;
}

/* ── Sources ── */
.sources-section {
  margin-top: 2.5rem;
  padding-top: 1.5rem;
  border-top: 1px solid var(--border);
}
.sources-section h3 {
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 600;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  color: var(--muted);
  margin-bottom: 0.75rem;
}
.sources-list {
  list-style: none;
  padding: 0;
}
.sources-list li {
  padding: 0.3rem 0;
}
.sources-list a {
  color: var(--accent);
  text-decoration: underline;
  text-decoration-color: var(--accent-subtle);
  text-underline-offset: 2px;
  font-size: 0.9rem;
}
.sources-list a:hover { text-decoration-color: var(--accent); }
.sources-list .source-name {
  font-family: var(--mono);
  font-size: 0.65rem;
  color: var(--muted);
  margin-left: 0.35rem;
}

/* ── Other articles ── */
.other-articles {
  margin-top: 2.5rem;
  padding-top: 1.5rem;
}
.other-articles h3 {
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 600;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  color: var(--muted);
  margin-bottom: 0.25rem;
}
.other-articles .oa-intro {
  font-size: 0.82rem;
  color: var(--muted);
  margin-bottom: 1rem;
}
.other-article-card {
  padding: 0.85rem 1rem;
  margin-bottom: 0.5rem;
  display: flex;
  align-items: center;
  gap: 1rem;
  border-radius: var(--radius-md);
  background: var(--bg-elevated);
  border: 1px solid var(--border);
  transition: all 0.15s;
}
.other-article-card:hover {
  border-color: var(--accent-subtle);
  background: var(--accent-light);
}
.oa-info {
  flex: 1;
  min-width: 0;
}
.oa-title {
  font-weight: 600;
  font-size: 0.9rem;
  margin-bottom: 0.1rem;
}
.oa-summary {
  font-size: 0.82rem;
  color: var(--ink-secondary);
  margin: 0.1rem 0;
  line-height: 1.4;
}
.oa-meta {
  font-family: var(--mono);
  font-size: 0.6rem;
  color: var(--muted);
  letter-spacing: 0.02em;
}
.oa-votes {
  display: flex;
  gap: 0.25rem;
  flex-shrink: 0;
}
.oa-toggle {
  display: none;
}
.oa-toggle-label {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  width: 34px; height: 34px;
  font-size: 0.9rem;
  border: 1px solid var(--border);
  cursor: pointer;
  transition: all 0.15s;
  background: var(--bg-elevated);
  user-select: none;
  border-radius: var(--radius-sm);
}
.oa-toggle-label:hover {
  background: var(--surface);
  border-color: var(--muted);
}
.oa-toggle:checked + .oa-toggle-label.vote-up {
  background: rgba(34,197,94,0.1);
  border-color: var(--green);
  color: var(--green);
}
.oa-toggle:checked + .oa-toggle-label.vote-down {
  background: rgba(239,68,68,0.08);
  border-color: var(--red);
  color: var(--red);
}
.oa-submit-row {
  margin-top: 1rem;
  display: flex;
  align-items: center;
  gap: 1rem;
}
.oa-submit-btn {
  font-family: var(--sans);
  font-size: 0.8rem;
  font-weight: 600;
  padding: 0.55rem 1.25rem;
  background: var(--ink);
  color: #fff;
  border: none;
  cursor: pointer;
  transition: all 0.15s;
  border-radius: var(--radius-md);
}
.oa-submit-btn:hover { background: #27272A; }
.oa-submit-btn:disabled {
  background: var(--surface);
  color: var(--muted);
  cursor: default;
}
.oa-submit-hint {
  font-size: 0.75rem;
  color: var(--muted);
}

/* ── Footer ── */
.session-footer {
  text-align: center;
  color: var(--muted);
  font-family: var(--mono);
  font-size: 0.6rem;
  letter-spacing: 0.06em;
  text-transform: uppercase;
  margin-top: 4rem;
  padding: 1.5rem 0 2.5rem;
  border-top: 1px solid var(--border);
}
.session-footer span { color: var(--ink); font-weight: 600; }

/* ── Responsive ── */
@media (max-width: 600px) {
  body { font-size: 16px; }
  .session-hero h1 { font-size: 1.75rem; }
  .step-number { width: 36px; height: 36px; font-size: 0.8rem; }
  .session-container { padding: 0 1.15rem 3rem; }
  .hero-meta { flex-wrap: wrap; gap: 0.75rem; }
  .agent-interaction { margin-left: 0; margin-right: 0; }
}
@media (prefers-reduced-motion: reduce) {
  * { transition: none !important; }
}
</style>
</head>
<body class="track-general">
  <div class="session-container">
    <a href="../index.html" class="back-link">&larr; Back to calendar</a>
    
    <div class="session-hero">
      <div class="hero-tag">Workshop</div>
      <h1>What if Your RAG Could Actually Think?</h1>
      <div class="hero-subtitle">PageIndex replaces vector similarity with LLM reasoning — and hits 98.7% accuracy on financial documents. Let&#x27;s build with it.</div>
      <div class="hero-meta">
        <span>40 min</span>
        <span> <span class="tag">RAG</span> <span class="tag">retrieval</span> <span class="tag">reasoning</span> <span class="tag">document-analysis</span> <span class="tag">PageIndex</span></span>
      </div>
    </div>
    <div class="context-block">
      <h2>What's happening</h2>
      <p>Here&#x27;s the uncomfortable truth about most RAG systems: they&#x27;re doing glorified keyword matching with extra steps. You chunk your documents, turn them into vectors, and then hope that cosine similarity — basically asking &quot;do these two things <em>sound</em> alike?&quot; — finds the right answer.</p>

<p>And honestly? For a lot of use cases, it works <em>fine</em>. But &quot;fine&quot; falls apart fast when you&#x27;re dealing with professional documents — financial reports, legal contracts, technical manuals. The kind of stuff where the answer to &quot;What was the company&#x27;s adjusted EBITDA excluding one-time restructuring charges?&quot; lives across three different sections and requires understanding what those terms actually mean.</p>

<p><strong>PageIndex</strong>, from VectifyAI, just dropped a framework that takes a completely different approach. Instead of vectorizing and searching, it builds a hierarchical tree — basically a smart table of contents — from your documents, then lets an LLM <em>reason its way</em> to the right pages. Think of it like the difference between Ctrl+F and actually reading the document with domain expertise.</p>

<p>The kicker? It hit <strong>98.7% accuracy on FinanceBench</strong>, a notoriously tricky benchmark for financial document Q&amp;A. That&#x27;s not a rounding error improvement — that&#x27;s a fundamentally different approach paying off. Let&#x27;s dig into how it works and build with it.</p>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">1</div>
        <h2>The Mental Model: Libraries, Not Search Engines</h2>
      </div>
      <div class="step-body">
        <p>Before we touch any code, let&#x27;s make sure we <em>get</em> what PageIndex is doing differently. This is the most important part of the whole workshop, honestly.</p>

<h3>Traditional Vector RAG: The Search Engine Approach</h3>

<p>Imagine you walk into a massive library and ask: &quot;What&#x27;s the company&#x27;s revenue guidance for next quarter?&quot; A vector RAG system would rip every page out of every book, throw them in a pile, and then find the pages that <em>sound most similar</em> to your question. It&#x27;s fast, it&#x27;s scalable, and it completely ignores the fact that those pages had context — they were in chapters, in sections, in a specific order for a reason.</p>

<h3>PageIndex: The Expert Librarian Approach</h3>

<p>Now imagine instead there&#x27;s an expert librarian. They know the layout of every shelf. They read your question, think &quot;Okay, that&#x27;s a forward-looking statement — I should check the earnings call transcript first, specifically the guidance section. If it&#x27;s not there, maybe the MD&amp;A section of the 10-K.&quot; They <em>navigate</em> to the right place using reasoning.</p>

<p>That&#x27;s PageIndex. It builds the equivalent of the librarian&#x27;s mental map (the tree index), then uses an LLM to navigate it (tree search).</p>

<h3>The AlphaGo Connection</h3>

<p>Here&#x27;s where it gets wild. The PageIndex team was inspired by <strong>AlphaGo</strong> — yes, the Go-playing AI. In Go, you can&#x27;t evaluate every possible move (there are more board positions than atoms in the universe). AlphaGo solved this with tree search — intelligently exploring the most promising branches. PageIndex applies the same idea: instead of comparing your query against every chunk, it navigates a tree of document sections, reasoning about which branches are most likely to contain the answer.</p>

<p>Let&#x27;s get our agent to help us understand the two-step architecture by building a comparison.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Get your agent to explain the PageIndex two-step architecture by creating a clear comparison with traditional vector RAG
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>What are the two main phases PageIndex uses? (Hint: indexing and retrieval)</li><li>How does a &#x27;tree index&#x27; differ from a vector index — what information does each preserve?</li><li>What role does the LLM play during retrieval in PageIndex vs. traditional RAG?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should lay out the two phases clearly: <strong>Step 1 — Tree Index Construction</strong>, where PageIndex parses the document&#x27;s natural structure (headings, sections, subsections) into a hierarchical tree, like an intelligent table of contents. <strong>Step 2 — Tree Search Retrieval</strong>, where given a query, an LLM starts at the root of the tree and reasons about which branches to explore, navigating down level by level until it reaches the most relevant pages. The key contrast: vector RAG treats retrieval as a <em>similarity lookup</em> (stateless, no context), while PageIndex treats it as a <em>reasoning task</em> (stateful, context-aware, multi-step).</p></div>
      </details>
      </div>
        
        
      <div class="callout callout-tip">
        <div class="callout-label">Tip</div>
        A good mental model: vector search asks &quot;what sounds like this?&quot; — tree search asks &quot;where would an expert look for this?&quot; Same question, fundamentally different thinking.
      </div>
        
      <details class="reveal">
        <summary>Why does similarity ≠ relevance?</summary>
        <div class="reveal-body"><p>Here&#x27;s a classic example: ask a financial RAG system &quot;What risks does the company face from AI regulation?&quot; A vector search might return paragraphs about AI technology the company <em>uses</em> (high similarity to &#x27;AI&#x27;) instead of the risk factors section that discusses regulatory threats (high <em>relevance</em> but different vocabulary). Relevance requires understanding intent and context — which is reasoning, not pattern matching. PageIndex&#x27;s tree search lets the LLM reason: &quot;This is a risk question → check the Risk Factors section → look for regulatory subsections → find AI-related risks.&quot; That chain of reasoning gets to relevance in a way similarity never can.</p></div>
      </details>
      <details class="reveal">
        <summary>How deep does the tree go?</summary>
        <div class="reveal-body"><p>The tree index typically mirrors the document&#x27;s natural hierarchy. For a 10-K filing, that might be: <strong>Level 0</strong> (root) → <strong>Level 1</strong> (Part I, Part II, Part III) → <strong>Level 2</strong> (Item 1 Business, Item 7 MD&amp;A, Item 8 Financial Statements) → <strong>Level 3</strong> (Revenue Discussion, Liquidity, Critical Accounting Policies) → <strong>Level 4</strong> (individual pages or paragraphs). The LLM doesn&#x27;t search every leaf — it prunes branches that aren&#x27;t relevant, just like a human would skip Part III (exhibits) when looking for revenue data.</p></div>
      </details>
      </div>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">2</div>
        <h2>Setting Up PageIndex: Let Your Agent Do the Wiring</h2>
      </div>
      <div class="step-body">
        <p>Alright, let&#x27;s actually get PageIndex running. The framework is open-source on GitHub and works as a Python library. We&#x27;re going to have our agent set everything up for us — installation, configuration, and the initial document indexing.</p>

<p>The basic flow is:</p>
<ol>
<li>Install PageIndex</li>
<li>Point it at a document (PDF, text, whatever)</li>
<li>Let it build the tree index</li>
<li>Query it with natural language</li>
</ol>

<p>The cool part is that the indexing step — where it builds that hierarchical tree — is where the magic happens. It&#x27;s parsing the document&#x27;s structure, not just splitting it into arbitrary 512-token chunks.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Get your agent to set up a minimal PageIndex project — install the library, configure an LLM provider, and build a tree index from a sample PDF
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>What Python package do you need, and what LLM provider will power the reasoning? (OpenAI, Anthropic, etc.)</li><li>What kind of document should you test with? Think about something with clear structure — sections, subsections, headings.</li><li>What does &#x27;building a tree index&#x27; actually produce? What would you want to see to verify it worked?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should give you a short setup script: <code>pip install pageindex</code> (or from the GitHub repo), configuring your API key for an LLM provider, then using PageIndex&#x27;s core API to load a PDF and generate a tree index. The key call looks something like:</p>

<p>```python</p>
<p>from pageindex import PageIndex</p>

<p>index = PageIndex(llm_provider=&quot;openai&quot;)</p>
<p>index.build(&quot;annual_report.pdf&quot;)</p>
<p>print(index.tree)  # shows the hierarchical structure</p>
<p>```</p>

<p>The output of <code>index.tree</code> is the hierarchical structure it discovered — essentially a nested table of contents with page references. If your document has clear sections (like a financial report), you should see a well-organized tree.</p></div>
      </details>
      </div>
        
        
      <div class="callout callout-api-key-note">
        <div class="callout-label">API Key Note</div>
        PageIndex uses an LLM under the hood for both indexing and retrieval. You&#x27;ll need an API key for your chosen provider (OpenAI, Anthropic, etc.). The indexing step makes API calls to understand document structure, so expect some token usage — a 50-page PDF might use a few thousand tokens for indexing.
      </div>
      <div class="callout callout-tip">
        <div class="callout-label">Tip</div>
        For your first test, use a document with obvious structure — an annual report, a technical spec, or even a well-organized research paper. PageIndex shines when there&#x27;s a real hierarchy to discover. A flat list of meeting notes? Not its best showcase.
      </div>
        
      <details class="reveal">
        <summary>What happens during tree index construction?</summary>
        <div class="reveal-body"><p>During indexing, PageIndex does something clever: it doesn&#x27;t just look at headings in the text. It uses the LLM to <em>understand</em> the document&#x27;s logical structure. If a PDF has inconsistent formatting (some sections are bold, some are numbered, some just have larger fonts), the LLM can still figure out the hierarchy. It&#x27;s basically asking: &quot;If a human expert were creating a table of contents for this document, what would it look like?&quot; The result is a tree where each node represents a logical section, with metadata about what pages it covers and what topics it contains.</p></div>
      </details>
      <details class="reveal">
        <summary>PageIndex vs. just asking the LLM to read the whole document</summary>
        <div class="reveal-body"><p>Fair question — if you have a powerful LLM with a long context window (like Claude with 200K tokens), why not just dump the whole document in? Two reasons: <strong>cost</strong> and <strong>accuracy</strong>. Feeding a 200-page annual report into every query is expensive and slow. More importantly, even long-context models can struggle with &quot;needle in a haystack&quot; problems — finding one specific detail in a sea of text. PageIndex gives the LLM a map so it knows exactly where to look, keeping the actual retrieval context small and focused.</p></div>
      </details>
      </div>
    </div>
    <div class="checkpoint">
      <div class="checkpoint-icon">&#10003;</div>
      <div>At this point, you should understand the core idea: PageIndex builds a tree (like a table of contents) from your document, then uses LLM reasoning to navigate that tree instead of vector similarity search. You should have the library installed and a tree index built from a sample document. If the tree structure looks reasonable — sections and subsections that match the document&#x27;s actual organization — you&#x27;re in great shape.</div>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">3</div>
        <h2>Querying the Tree: Watch Reasoning Replace Similarity</h2>
      </div>
      <div class="step-body">
        <p>Now for the fun part — actually asking questions. This is where you&#x27;ll see the difference between &quot;find me something that sounds like this&quot; and &quot;reason about where to look.&quot;</p>

<p>When you send a query to PageIndex, here&#x27;s what happens under the hood:</p>

<ol>
<li>The LLM reads your question and the <strong>root level</strong> of the tree (the top-level sections)</li>
<li>It reasons: &quot;This question is about X, which most likely lives in section Y&quot;</li>
<li>It navigates down to section Y and sees its children (subsections)</li>
<li>It reasons again: &quot;Within Y, subsection Z is most relevant&quot;</li>
<li>It keeps going until it reaches the actual pages/paragraphs</li>
<li>Those pages become the context for answering your question</li>
</ol>

<p>It&#x27;s literally the LLM <em>thinking out loud</em> about where to look. And because it&#x27;s reasoning at each level, it can handle complex queries that require understanding context — not just matching keywords.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Get your agent to build a complete query pipeline — take a natural language question, run it through PageIndex&#x27;s tree search, retrieve the relevant pages, and generate an answer
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>What kind of question would really show off tree search vs. vector search? Think multi-step or domain-specific.</li><li>How should the retrieved context be passed to the LLM for final answer generation?</li><li>What would you want to see in the output to verify the *reasoning* path — not just the answer?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should give you a short querying script that sends a question to your indexed document and returns both the <strong>answer</strong> and the <strong>retrieval path</strong> — which sections the LLM navigated through to find the relevant pages. The key part:</p>

<p>```python</p>
<p>result = index.query(&quot;What was the adjusted EBITDA?&quot;)</p>
<p>print(result.answer)       # the final answer</p>
<p>print(result.path)         # the tree navigation path</p>
<p>print(result.source_pages) # which pages it pulled from</p>
<p>```</p>

<p>The retrieval path is the gold — you should see something like: <code>Root → Financial Statements → Income Statement → Non-GAAP Reconciliation</code>. That&#x27;s the LLM reasoning its way through the tree, not just doing a similarity lookup.</p></div>
      </details>
      </div>
        
        
      <div class="callout callout-tip">
        <div class="callout-label">Tip</div>
        Try the same question on both PageIndex and a traditional vector RAG system (if you have one). The answers might be similar for simple questions, but for anything requiring context — like &#x27;How did revenue change year-over-year and what drove it?&#x27; — the tree search will pull from the right sections while vector search might grab scattered, decontextualized chunks.
      </div>
        
      <details class="reveal">
        <summary>What makes a &#x27;good&#x27; question for PageIndex?</summary>
        <div class="reveal-body"><p>PageIndex really shines on questions that a naive keyword/similarity search would botch:</p>

<ul>
<li><strong>Cross-referencing questions</strong>: &quot;Compare the risk factors mentioned in the 10-K with the opportunities discussed in the shareholder letter&quot; — requires navigating to two different sections.</li>
<li><strong>Domain-specific questions</strong>: &quot;What&#x27;s the company&#x27;s exposure to variable-rate debt?&quot; — requires understanding that this lives in the liquidity/capital resources section, not just matching &#x27;debt&#x27;.</li>
<li><strong>Negative/absence questions</strong>: &quot;Did the company mention any cybersecurity incidents?&quot; — vector search struggles with negation; tree search can systematically check the right sections.</li>
<li><strong>Multi-hop questions</strong>: &quot;Based on the revenue growth rate and the capex guidance, what&#x27;s the implied return on investment?&quot; — requires pulling from multiple specific sections and reasoning across them.</li>
</ul></div>
      </details>
      </div>
    </div>
    <div class="decision-point">
      <h3>Quick Check</h3>
      <div class="question">You&#x27;re building a RAG system for a law firm that needs to answer questions about 500-page contracts. A lawyer asks: &quot;Does this contract have a non-compete clause, and if so, does it apply after termination?&quot; Which retrieval approach is better suited for this?</div>
      
        <div class="decision-option">
          <input type="radio" name="decision_6" id="decision_6_opt0">
          <label for="decision_6_opt0">Tree-based reasoning (PageIndex style)</label>
          <div class="decision-feedback correct">&#10003; Correct! This is a two-part question requiring navigation to specific contract sections. A tree search would reason: &#x27;Non-compete → check Restrictive Covenants or Post-Termination Obligations sections → look for duration and scope clauses.&#x27; It understands the document&#x27;s legal structure and can check both the non-compete section AND the termination section, then connect the dots. Vector search might find the non-compete clause but miss the termination-specific provisions that modify it.</div>
        </div>
        <div class="decision-option">
          <input type="radio" name="decision_6" id="decision_6_opt1">
          <label for="decision_6_opt1">Vector similarity search (traditional RAG)</label>
          <div class="decision-feedback incorrect">&#10007; Not quite. Vector search would find chunks containing &#x27;non-compete&#x27; and &#x27;termination&#x27; — but it wouldn&#x27;t understand that these concepts interact across sections. The non-compete clause might say &#x27;subject to Section 12.4&#x27; and the termination section might modify the duration — vector search would likely miss this cross-reference because those chunks wouldn&#x27;t be similar to the query. For structured documents where information is organized hierarchically, reasoning-based retrieval wins.</div>
        </div>
        <div class="decision-option">
          <input type="radio" name="decision_6" id="decision_6_opt2">
          <label for="decision_6_opt2">Full document in context window (just dump it all in)</label>
          <div class="decision-feedback incorrect">&#10007; Not quite. At 500 pages, you&#x27;re looking at roughly 200K+ tokens — possibly exceeding context limits, definitely expensive per query, and even long-context models can lose track of specific clauses in that much text. More practically, if the law firm is running hundreds of queries a day across many contracts, the cost becomes prohibitive. Tree indexing gives you precision without the context window tax.</div>
        </div>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">4</div>
        <h2>Building the Comparison: Vector RAG vs. PageIndex Side-by-Side</h2>
      </div>
      <div class="step-body">
        <p>Okay, claiming something is better is easy. <em>Showing</em> it is what matters. Let&#x27;s build a quick comparison pipeline so you can see the difference with your own documents.</p>

<p>The idea is simple: take the same document and the same questions, run them through both a traditional vector RAG pipeline and PageIndex, and compare the results. Not just the answers — the <em>retrieval quality</em>. Which chunks or pages did each system pull? Were they actually relevant?</p>

<p>This is where the 98.7% FinanceBench number comes from — PageIndex didn&#x27;t just get more answers right, it consistently retrieved more relevant context. And relevance of retrieved context is the whole game in RAG. Your LLM can only give a good answer if it&#x27;s looking at the right information.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Get your agent to build a simple side-by-side comparison: a basic vector RAG pipeline (using any embedding model + similarity search) and a PageIndex pipeline, both answering the same questions from the same document
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>For the vector RAG side, what&#x27;s the simplest setup? Think: embed chunks, store them, retrieve top-k by similarity.</li><li>What metrics should you compare? Think beyond just &#x27;correct answer&#x27; — retrieval precision, context relevance, and explainability.</li><li>How would you structure the output so the comparison is clear and visual?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should give you a comparison script with two paths: one using a simple vector pipeline (something like <code>langchain</code> or raw OpenAI embeddings with a basic vector store) and one using PageIndex. For each test question, it runs both systems and shows: the retrieved chunks/pages, the final answer, and whether the context was actually relevant. The output should look like a side-by-side table:</p>

<ul>
<li><strong>Question</strong>: &quot;What was the year-over-year revenue change?&quot;</li>
<li><strong>Vector RAG</strong>: Retrieved 3 chunks mentioning &#x27;revenue&#x27; — but one was from a risk factors boilerplate, not actual numbers. Answer: partially correct.</li>
<li><strong>PageIndex</strong>: Navigated to Financial Highlights → Revenue Discussion → pulled the exact comparison table. Answer: correct with specific numbers.</li>
</ul>

<p>The key insight: both might sometimes get the same answer, but PageIndex&#x27;s retrieved context is consistently more <em>targeted</em>.</p></div>
      </details>
      </div>
        
        
      <div class="callout callout-warning">
        <div class="callout-label">Warning</div>
        Be honest about the tradeoffs. PageIndex uses more LLM calls per query (it reasons at each tree level), so it&#x27;s slower and potentially more expensive per query than vector search. Vector RAG is still great for high-volume, lower-stakes retrieval where speed matters more than precision. The right choice depends on your use case.
      </div>
        
      <details class="reveal">
        <summary>When should you still use vector RAG?</summary>
        <div class="reveal-body"><p>PageIndex isn&#x27;t a silver bullet. Vector RAG is still the better choice when:</p>

<ul>
<li><strong>Speed is critical</strong>: Vector lookup is milliseconds; tree reasoning takes seconds.</li>
<li><strong>Documents lack structure</strong>: If your corpus is a pile of unstructured emails or chat logs, there&#x27;s no meaningful tree to build.</li>
<li><strong>Scale is massive</strong>: Searching across 10 million documents? Vector indices are built for that scale. PageIndex is optimized for deep retrieval within individual long documents.</li>
<li><strong>Questions are simple</strong>: &quot;What&#x27;s the CEO&#x27;s name?&quot; doesn&#x27;t need multi-step reasoning — similarity search handles it fine.</li>
</ul>

<p>The sweet spot for PageIndex is <strong>long, structured, professional documents</strong> where precision matters: financial filings, legal contracts, technical documentation, medical records. If your documents have chapters, sections, and subsections, PageIndex will likely outperform vector search.</p></div>
      </details>
      <details class="reveal">
        <summary>Can you combine both approaches?</summary>
        <div class="reveal-body"><p>Absolutely, and this is honestly where things get interesting. You could use vector search as a <em>first pass</em> to identify which documents in a large corpus are relevant, then use PageIndex for <em>deep retrieval</em> within those documents. Think of it as: vector search finds the right book in the library, PageIndex finds the right page in that book. Some teams are calling this &#x27;hybrid retrieval&#x27; and it combines the scale of vector search with the precision of reasoning-based retrieval.</p></div>
      </details>
      </div>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">5</div>
        <h2>Vision-Based RAG: When Your Documents Are Images</h2>
      </div>
      <div class="step-body">
        <p>Here&#x27;s a bonus that honestly blew my mind when I first saw it. PageIndex also supports <strong>vision-based vectorless RAG</strong> — meaning you can skip OCR entirely and work directly with PDF page images.</p>

<p>Think about what this means: scanned documents, complex tables, charts with annotations, handwritten notes in margins — all the stuff that makes traditional text-based RAG cry. Instead of trying to extract text (and mangling tables in the process), PageIndex can use a vision-capable LLM to look at the actual page images and reason about them.</p>

<p>The tree index still works the same way — it organizes pages hierarchically. But during retrieval, instead of feeding the LLM extracted text, it feeds page images. The LLM literally <em>looks at</em> the relevant pages, tables and all.</p>

<p>This is particularly huge for financial documents where tables carry most of the important information, and OCR-based extraction routinely mangles column alignment.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Get your agent to explain how you&#x27;d modify the basic PageIndex setup to use vision-based retrieval instead of text-based, and what types of documents benefit most
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>What LLM capabilities does vision-based RAG require that text-based doesn&#x27;t?</li><li>What types of document content are poorly served by text extraction but work great with vision?</li><li>How does the tree index change (or not change) when working with images vs. text?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should explain that switching to vision-based mode primarily means: using a vision-capable LLM (GPT-4o, Claude with vision, etc.), keeping PDF pages as images instead of extracting text, and passing those images directly to the LLM during both indexing and retrieval. The tree structure is still built the same way — it&#x27;s just that the LLM &#x27;reads&#x27; page images instead of extracted text. The agent should highlight that this is especially powerful for documents with complex tables, charts, diagrams, or mixed layouts where OCR would lose information. No code change is dramatic — it&#x27;s mostly a configuration switch in how PageIndex processes the source document.</p></div>
      </details>
      </div>
        
        
      <div class="callout callout-tip">
        <div class="callout-label">Tip</div>
        Vision-based RAG is more expensive per query (image tokens cost more than text tokens) but can be dramatically more accurate for visually complex documents. If your document has a table that looks perfect in the PDF but turns into garbage after OCR, vision-based is the way to go.
      </div>
        
      </div>
    </div>
    <div class="checkpoint">
      <div class="checkpoint-icon">&#10003;</div>
      <div>You should now have a solid understanding of the full PageIndex pipeline: tree index construction from document structure, reasoning-based tree search for retrieval, and the option for vision-based processing. You should also understand *when* this approach beats vector search (structured, professional documents requiring precision) and when it doesn&#x27;t (massive scale, unstructured data, simple queries). Most importantly, you should be able to explain to someone *why* similarity ≠ relevance.</div>
    </div>
    <div class="your-turn">
      <h3>Your Turn</h3>
      <div class="your-turn-goal">Build a multi-document PageIndex system that can answer questions spanning multiple financial reports — for example, comparing a company&#x27;s performance across three annual reports</div>
      <div class="your-turn-context">Real-world financial analysis rarely looks at a single document in isolation. Analysts compare year-over-year trends, cross-reference quarterly earnings with annual filings, and look for inconsistencies across reports. Can PageIndex handle this? You&#x27;ll need to think about how the tree index works across multiple documents and how the reasoning step changes when the answer might come from any of several sources.</div>
      
      <div class="agent-hints">
        <div class="agent-hints-label">Think about it</div>
        <ul><li>How would you structure the tree when you have multiple documents? One big tree or separate trees with a meta-index?</li><li>What happens during the reasoning step if the LLM needs to pull from two different annual reports to answer a comparison question?</li><li>How would you tell the agent to handle conflicting information between documents?</li></ul>
      </div>
      
      <details class="reveal">
        <summary>See a sample prompt</summary>
        <div class="reveal-body">
          <div class="code-block">
            <span class="code-caption">One way you could prompt it</span>
            <button class="copy-btn">COPY</button>
            <pre><code>Build me a PageIndex system that can load 3 annual reports (2022, 2023, 2024) for the same company. Create individual tree indices for each report, then build a meta-index that maps years to their trees. When I ask a question like &#x27;How did the company&#x27;s debt-to-equity ratio change from 2022 to 2024?&#x27;, the system should: 1) Reason about which reports to check, 2) Navigate each relevant tree to find the balance sheet / capital structure sections, 3) Pull the specific numbers from each year, and 4) Synthesize a comparison answer with citations showing which pages from which reports the data came from. Show me the retrieval path for each document so I can verify it found the right sections.</code></pre>
          </div>
        </div>
      </details>
    </div>
    <div class="recap-section">
      <h2>Recap</h2>
      <div class="recap-body"><p>Let&#x27;s step back and look at what we just explored. PageIndex represents a genuinely different philosophy about retrieval: instead of treating it as a search problem (find similar things), it treats it as a <strong>reasoning problem</strong> (figure out where an expert would look).</p>

<p>We walked through the two-step architecture — building a hierarchical tree index from document structure, then using LLM reasoning to navigate that tree. We saw why this matters: similarity search can find things that <em>sound</em> like your question, but reasoning-based search finds things that are actually <em>relevant</em> to your question. And for professional documents where precision matters, that difference is everything.</p>

<p>The 98.7% accuracy on FinanceBench isn&#x27;t just a benchmark number — it reflects a fundamental insight: <strong>documents have structure for a reason</strong>, and retrieval systems that respect that structure will always have an advantage over systems that throw it away.</p>

<p>This is honestly one of those ideas that seems obvious in hindsight. Of course an expert doesn&#x27;t search for similar words — they navigate to the right section. PageIndex just gives LLMs that same ability.</p></div>
      <ul class="takeaways-list"><li>Similarity ≠ relevance. Vector search finds things that sound like your query; reasoning-based search finds things that actually answer it. For complex, professional documents, that distinction is critical.</li><li>Document structure is information, not noise. Traditional RAG discards hierarchy by chunking — PageIndex preserves it as a tree and uses it for navigation. Treating your document like a table of contents instead of a bag of words fundamentally changes retrieval quality.</li><li>The right retrieval approach depends on your use case. PageIndex excels at deep, precise retrieval within long structured documents. Vector RAG excels at broad search across massive, unstructured corpora. The best production systems may combine both.</li><li>Explainability is a feature, not a nice-to-have. PageIndex shows you the reasoning path — which sections it explored and why. When your RAG system is making decisions that matter (financial, legal, medical), being able to trace how it got its answer is invaluable.</li></ul>
      
      <div class="next-steps">
        <h3>Where to go next</h3>
        <ul><li>Try the official PageIndex Vectorless RAG cookbook on GitHub — it&#x27;s a minimal, runnable notebook that walks through the full pipeline with a real document</li><li>Experiment with vision-based RAG on a document with complex tables or charts — see how it compares to text extraction approaches</li><li>Build a hybrid pipeline: use vector search to find relevant documents from a large corpus, then use PageIndex for precise retrieval within the top results</li><li>Check out the PageIndex MCP integration if you want to plug reasoning-based retrieval directly into Claude or other AI assistants</li></ul>
      </div>
    </div>
    <div class="sources-section">
      <h3>Sources</h3>
      <ul class="sources-list"><li><a href="https://github.com/VectifyAI/PageIndex" target="_blank" rel="noopener">VectifyAI/PageIndex</a> <span class="source-name">(GitHub Trending Python)</span></li></ul>
    </div>
    <div class="other-articles">
      <h3>What else was in the news</h3>
      <p class="oa-intro">These articles were also available today. Vote to help shape future sessions.</p>
      
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">ComposioHQ/awesome-claude-skills</div>
            <div class="oa-summary">Curated collection of Claude Skills and tools for customizing AI-assisted workflows and boosting productivity.</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_0" value="up" id="vote_0_up" class="oa-toggle" data-idx="0">
            <label for="vote_0_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_0" value="down" id="vote_0_down" class="oa-toggle" data-idx="0">
            <label for="vote_0_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">datagouv/datagouv-mcp</div>
            <div class="oa-summary">MCP server letting AI chatbots search and analyze French government open data through conversation.</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_1" value="up" id="vote_1_up" class="oa-toggle" data-idx="1">
            <label for="vote_1_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_1" value="down" id="vote_1_down" class="oa-toggle" data-idx="1">
            <label for="vote_1_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">Don&#x27;t trust AI agents</div>
            <div class="oa-summary">Argues AI agents pose serious security risks and shouldn&#x27;t be trusted with autonomous access to systems.</div>
            <div class="oa-meta">Hacker News AI · Feb 28</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_2" value="up" id="vote_2_up" class="oa-toggle" data-idx="2">
            <label for="vote_2_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_2" value="down" id="vote_2_down" class="oa-toggle" data-idx="2">
            <label for="vote_2_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">521xueweihan/HelloGitHub</div>
            <div class="oa-summary">Monthly newsletter showcasing interesting, beginner-friendly open source projects discovered on GitHub.</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_3" value="up" id="vote_3_up" class="oa-toggle" data-idx="3">
            <label for="vote_3_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_3" value="down" id="vote_3_down" class="oa-toggle" data-idx="3">
            <label for="vote_3_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">ruvnet/wifi-densepose</div>
            <div class="oa-summary">Estimates full-body human poses through walls using standard WiFi routers instead of cameras.</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_4" value="up" id="vote_4_up" class="oa-toggle" data-idx="4">
            <label for="vote_4_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_4" value="down" id="vote_4_down" class="oa-toggle" data-idx="4">
            <label for="vote_4_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">I built a demo of what AI chat will look like when it&#x27;s &quot;free&quot; and ad-supported</div>
            <div class="oa-summary">Interactive demo showing how ad-supported free AI chat could work, sparking debate about AI business models.</div>
            <div class="oa-meta">Hacker News AI · Mar 1</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_5" value="up" id="vote_5_up" class="oa-toggle" data-idx="5">
            <label for="vote_5_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_5" value="down" id="vote_5_down" class="oa-toggle" data-idx="5">
            <label for="vote_5_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">AI Made Writing Code Easier. It Made Being an Engineer Harder</div>
            <div class="oa-summary">Argues AI coding tools simplify writing code but increase the cognitive demands of real engineering work.</div>
            <div class="oa-meta">Hacker News AI · Mar 1</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_6" value="up" id="vote_6_up" class="oa-toggle" data-idx="6">
            <label for="vote_6_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_6" value="down" id="vote_6_down" class="oa-toggle" data-idx="6">
            <label for="vote_6_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">OpenFang</div>
            <div class="oa-summary">Open-source operating system for building, deploying, and managing autonomous AI agents.</div>
            <div class="oa-meta">Product Hunt AI · Mar 1</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_7" value="up" id="vote_7_up" class="oa-toggle" data-idx="7">
            <label for="vote_7_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_7" value="down" id="vote_7_down" class="oa-toggle" data-idx="7">
            <label for="vote_7_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">Running a One Trillion-Parameter LLM Locally on AMD Ryzen AI Max+ Cluster</div>
            <div class="oa-summary">AMD demonstrates running a one-trillion-parameter language model locally on a cluster of Ryzen AI laptops.</div>
            <div class="oa-meta">Hacker News AI · Mar 1</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_8" value="up" id="vote_8_up" class="oa-toggle" data-idx="8">
            <label for="vote_8_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_8" value="down" id="vote_8_down" class="oa-toggle" data-idx="8">
            <label for="vote_8_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">What AI coding costs you</div>
            <div class="oa-summary">Explores the hidden tradeoffs and real costs of relying on AI tools for software development.</div>
            <div class="oa-meta">Hacker News AI · Feb 28</div>
          </div>
          <div class="oa-votes">
            <input type="radio" name="vote_9" value="up" id="vote_9_up" class="oa-toggle" data-idx="9">
            <label for="vote_9_up" class="oa-toggle-label vote-up" title="More like this">&#x25B2;</label>
            <input type="radio" name="vote_9" value="down" id="vote_9_down" class="oa-toggle" data-idx="9">
            <label for="vote_9_down" class="oa-toggle-label vote-down" title="Not interested">&#x25BC;</label>
          </div>
        </div>
      <div class="oa-submit-row">
        <button id="oa-submit" class="oa-submit-btn" disabled>Submit votes</button>
        <span id="oa-hint" class="oa-submit-hint">Select at least one vote</span>
      </div>
    </div>
    <script>
    (function() {
      var articles = [{"title": "ComposioHQ/awesome-claude-skills", "tags": "tools,coding", "source": "GitHub Trending Python"}, {"title": "datagouv/datagouv-mcp", "tags": "tools", "source": "GitHub Trending Python"}, {"title": "Don't trust AI agents", "tags": "agents", "source": "Hacker News AI"}, {"title": "521xueweihan/HelloGitHub", "tags": "open-source", "source": "GitHub Trending Python"}, {"title": "ruvnet/wifi-densepose", "tags": "", "source": "GitHub Trending Python"}, {"title": "I built a demo of what AI chat will look like when it's \"free\" and ad-supported", "tags": "tools", "source": "Hacker News AI"}, {"title": "AI Made Writing Code Easier. It Made Being an Engineer Harder", "tags": "coding", "source": "Hacker News AI"}, {"title": "OpenFang", "tags": "agents,open-source", "source": "Product Hunt AI"}, {"title": "Running a One Trillion-Parameter LLM Locally on AMD Ryzen AI Max+ Cluster", "tags": "coding", "source": "Hacker News AI"}, {"title": "What AI coding costs you", "tags": "coding", "source": "Hacker News AI"}];
      var repo = "coldbrewnosugar/ai-course";
      var track = "general";
      var date = "2026-03-01";

      var toggles = document.querySelectorAll('.oa-toggle');
      var btn = document.getElementById('oa-submit');
      var hint = document.getElementById('oa-hint');

      function updateBtn() {
        var any = false;
        toggles.forEach(function(t) { if (t.checked) any = true; });
        btn.disabled = !any;
        hint.textContent = any ? '' : 'Select at least one vote';
      }
      toggles.forEach(function(t) { t.addEventListener('change', updateBtn); });

      btn.addEventListener('click', function() {
        var lines = [];
        for (var i = 0; i < articles.length; i++) {
          var up = document.getElementById('vote_' + i + '_up');
          var down = document.getElementById('vote_' + i + '_down');
          var vote = '';
          if (up && up.checked) vote = 'up';
          if (down && down.checked) vote = 'down';
          if (vote) {
            lines.push(vote + ' | ' + articles[i].title + ' | tags:' + articles[i].tags + ' | source:' + articles[i].source);
          }
        }
        if (lines.length === 0) return;

        var body = 'track:' + track + '\ndate:' + date + '\n\n' + lines.join('\n');
        var title = 'Votes from ' + date + ' (' + track + ')';
        var url = 'https://github.com/' + repo + '/issues/new?labels=vote&title=' +
          encodeURIComponent(title) + '&body=' + encodeURIComponent(body);
        window.open(url, '_blank');
      });
    })();</script>
    <footer class="session-footer">
      <span>Tinker</span> &middot; Build with AI, daily
    </footer>
  </div>
  <script>
document.addEventListener('DOMContentLoaded', function() {
  // Copy-to-clipboard
  document.querySelectorAll('.copy-btn').forEach(function(btn) {
    btn.addEventListener('click', function() {
      var code = btn.closest('.code-block').querySelector('code').textContent;
      navigator.clipboard.writeText(code).then(function() {
        btn.textContent = 'COPIED';
        btn.classList.add('copied');
        setTimeout(function() {
          btn.textContent = 'COPY';
          btn.classList.remove('copied');
        }, 2000);
      });
    });
  });
});
</script>
</body>
</html>