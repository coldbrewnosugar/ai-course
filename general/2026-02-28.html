<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Context Mode: Shrink MCP Output by 98% in Claude Code — Tinker</title>
  <style>
@import url('https://fonts.googleapis.com/css2?family=Space+Mono:wght@400;700&family=DM+Sans:wght@300;400;500;600;700&display=swap');
:root {
  --bg: #ffffff;
  --ink: #0a0a0a;
  --ink-secondary: #333;
  --muted: #888;
  --red: #E63226;
  --blue: #1B3F8B;
  --yellow: #F5B731;
  --green: #1a8754;
  --light-gray: #f6f6f6;
  --border-gray: #e0e0e0;
  --mono: 'Space Mono', monospace;
  --sans: 'DM Sans', system-ui, sans-serif;
  --border: 2px solid var(--ink);
  --max-w: 720px;
}
*, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }
body {
  font-family: var(--sans);
  background: var(--bg);
  color: var(--ink);
  min-height: 100vh;
  -webkit-font-smoothing: antialiased;
  line-height: 1.7;
  font-size: 17px;
}

/* ── Layout ── */
.session-container {
  max-width: var(--max-w);
  margin: 0 auto;
  padding: 0 1.5rem 4rem;
}

/* ── Back link ── */
.back-link {
  display: inline-flex;
  align-items: center;
  gap: 0.4rem;
  font-family: var(--mono);
  font-size: 0.7rem;
  font-weight: 700;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  color: var(--muted);
  text-decoration: none;
  padding: 1.5rem 0 1rem;
  transition: color 0.15s;
}
.back-link:hover { color: var(--ink); }

/* ── Hero ── */
.session-hero {
  border-bottom: 3px solid var(--ink);
  padding: 2.5rem 0 2rem;
  margin-bottom: 2.5rem;
}
.session-hero .hero-tag {
  display: inline-block;
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 700;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  color: #fff;
  background: var(--red);
  padding: 0.25rem 0.75rem;
  margin-bottom: 1rem;
}
.session-hero h1 {
  font-family: var(--mono);
  font-size: 2rem;
  font-weight: 700;
  line-height: 1.15;
  letter-spacing: -0.02em;
  margin-bottom: 0.5rem;
}
.session-hero .hero-subtitle {
  font-size: 1.1rem;
  color: var(--ink-secondary);
  font-weight: 400;
}
.session-hero .hero-meta {
  display: flex;
  gap: 1.5rem;
  margin-top: 1rem;
  font-family: var(--mono);
  font-size: 0.7rem;
  color: var(--muted);
  letter-spacing: 0.04em;
}
.hero-meta .tag {
  display: inline-block;
  background: var(--light-gray);
  border: 1px solid var(--border-gray);
  padding: 0.15rem 0.5rem;
  font-size: 0.65rem;
}

/* ── Section divider ── */
.section-divider {
  border: none;
  border-top: 3px solid var(--ink);
  margin: 3rem 0;
}

/* ── Context block ── */
.context-block {
  background: var(--light-gray);
  border-left: 4px solid var(--ink);
  padding: 1.5rem 1.75rem;
  margin-bottom: 2.5rem;
}
.context-block h2 {
  font-family: var(--mono);
  font-size: 0.7rem;
  font-weight: 700;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  color: var(--muted);
  margin-bottom: 0.75rem;
}
.context-block p { margin-bottom: 0.75rem; }
.context-block p:last-child { margin-bottom: 0; }

/* ── Steps ── */
.step-section { margin-bottom: 3rem; }
.step-header {
  display: flex;
  align-items: flex-start;
  gap: 1rem;
  margin-bottom: 1.5rem;
}
.step-number {
  flex-shrink: 0;
  width: 48px; height: 48px;
  background: var(--ink);
  color: #fff;
  font-family: var(--mono);
  font-size: 1.2rem;
  font-weight: 700;
  display: flex;
  align-items: center;
  justify-content: center;
}
.step-header h2 {
  font-family: var(--mono);
  font-size: 1.25rem;
  font-weight: 700;
  line-height: 1.2;
  padding-top: 0.3rem;
}
.step-body p { margin-bottom: 0.75rem; }
.step-body ul, .step-body ol { margin: 0.5rem 0 0.75rem 1.5rem; }
.step-body li { margin-bottom: 0.3rem; }
.step-body strong { font-weight: 600; }
.step-body a { color: var(--blue); }

/* ── Code blocks ── */
.code-block {
  position: relative;
  margin: 1.25rem 0;
  background: var(--light-gray);
  border: 1px solid var(--border-gray);
  border-left: 4px solid var(--blue);
}
.code-caption {
  display: block;
  padding: 0.5rem 1rem;
  font-family: var(--mono);
  font-size: 0.7rem;
  font-weight: 700;
  color: var(--muted);
  border-bottom: 1px solid var(--border-gray);
  letter-spacing: 0.04em;
}
.code-block pre {
  padding: 1rem;
  overflow-x: auto;
  margin: 0;
}
.code-block code {
  font-family: var(--mono);
  font-size: 0.85rem;
  line-height: 1.5;
  color: var(--ink);
}
.copy-btn {
  position: absolute;
  top: 0.4rem;
  right: 0.5rem;
  font-family: var(--mono);
  font-size: 0.6rem;
  font-weight: 700;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  background: var(--ink);
  color: #fff;
  border: none;
  padding: 0.3rem 0.6rem;
  cursor: pointer;
  transition: background 0.15s;
}
.copy-btn:hover { background: var(--blue); }
.copy-btn.copied { background: var(--green); }

/* ── Callouts ── */
.callout {
  border-left: 4px solid;
  padding: 1rem 1.25rem;
  margin: 1.25rem 0;
  font-size: 0.95rem;
}
.callout-tip {
  border-color: var(--blue);
  background: rgba(27,63,139,0.05);
}
.callout-warning {
  border-color: var(--red);
  background: rgba(230,50,38,0.05);
}
.callout-api-key-note {
  border-color: var(--yellow);
  background: rgba(245,183,49,0.1);
}
.callout-label {
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 700;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  margin-bottom: 0.3rem;
}
.callout-tip .callout-label { color: var(--blue); }
.callout-warning .callout-label { color: var(--red); }
.callout-api-key-note .callout-label { color: #b8860b; }

/* ── Reveals (details/summary) ── */
.reveal {
  margin: 1rem 0;
  border: 1px solid var(--border-gray);
}
.reveal summary {
  font-family: var(--mono);
  font-size: 0.85rem;
  font-weight: 700;
  padding: 0.75rem 1rem;
  cursor: pointer;
  background: var(--light-gray);
  list-style: none;
  display: flex;
  align-items: center;
  gap: 0.5rem;
  transition: background 0.15s;
}
.reveal summary:hover { background: #eee; }
.reveal summary::before {
  content: "\25B6";
  font-size: 0.6rem;
  transition: transform 0.2s;
}
.reveal[open] summary::before {
  transform: rotate(90deg);
}
.reveal .reveal-body {
  padding: 1rem;
  border-top: 1px solid var(--border-gray);
  font-size: 0.95rem;
}
.reveal .reveal-body p { margin-bottom: 0.5rem; }
.reveal .reveal-body p:last-child { margin-bottom: 0; }

/* ── Checkpoint ── */
.checkpoint {
  display: flex;
  align-items: center;
  gap: 1rem;
  padding: 1.25rem 1.5rem;
  background: var(--ink);
  color: #fff;
  margin: 2rem 0;
  font-family: var(--mono);
  font-size: 0.85rem;
  font-weight: 700;
  letter-spacing: 0.02em;
}
.checkpoint-icon {
  flex-shrink: 0;
  width: 32px; height: 32px;
  border: 2px solid #fff;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 1rem;
}

/* ── Decision point ── */
.decision-point {
  border: 2px solid var(--ink);
  margin: 2rem 0;
  padding: 1.5rem;
}
.decision-point h3 {
  font-family: var(--mono);
  font-size: 0.7rem;
  font-weight: 700;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  color: var(--muted);
  margin-bottom: 0.5rem;
}
.decision-point .question {
  font-size: 1.1rem;
  font-weight: 600;
  margin-bottom: 1rem;
}
.decision-option {
  margin-bottom: 0.75rem;
}
.decision-option input[type="radio"] {
  display: none;
}
.decision-option label {
  display: block;
  padding: 0.75rem 1rem;
  border: 1px solid var(--border-gray);
  cursor: pointer;
  transition: all 0.15s;
  font-weight: 500;
}
.decision-option label:hover {
  border-color: var(--ink);
  background: var(--light-gray);
}
.decision-option input:checked + label {
  border-color: var(--ink);
  border-width: 2px;
  background: var(--light-gray);
}
.decision-feedback {
  display: none;
  padding: 0.75rem 1rem;
  margin-top: 0.25rem;
  font-size: 0.9rem;
  border-left: 3px solid;
}
.decision-option input:checked ~ .decision-feedback {
  display: block;
}
.decision-feedback.correct {
  border-color: var(--green);
  background: rgba(26,135,84,0.05);
  color: var(--green);
}
.decision-feedback.incorrect {
  border-color: var(--red);
  background: rgba(230,50,38,0.05);
  color: var(--red);
}

/* ── Agent interaction ── */
.agent-interaction {
  margin: 1.5rem 0;
  border: 2px solid var(--ink);
}
.agent-goal {
  padding: 1rem 1.25rem;
  background: var(--ink);
  color: #fff;
  font-family: var(--mono);
  font-size: 0.85rem;
  font-weight: 700;
}
.agent-goal-label {
  font-size: 0.6rem;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  color: rgba(255,255,255,0.6);
  margin-bottom: 0.3rem;
}
.agent-hints {
  padding: 1rem 1.25rem;
  background: rgba(27,63,139,0.04);
  border-bottom: 1px solid var(--border-gray);
}
.agent-hints-label {
  font-family: var(--mono);
  font-size: 0.6rem;
  font-weight: 700;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  color: var(--blue);
  margin-bottom: 0.5rem;
}
.agent-hints ul {
  list-style: none;
  padding: 0;
}
.agent-hints li {
  padding: 0.3rem 0 0.3rem 1.5rem;
  position: relative;
  font-size: 0.95rem;
  font-style: italic;
  color: var(--ink-secondary);
}
.agent-hints li::before {
  content: "?";
  position: absolute;
  left: 0;
  color: var(--blue);
  font-weight: 700;
  font-style: normal;
  font-family: var(--mono);
}

/* ── Your turn ── */
.your-turn {
  border: 2px solid var(--blue);
  padding: 1.5rem;
  margin: 2rem 0;
}
.your-turn h3 {
  font-family: var(--mono);
  font-size: 0.7rem;
  font-weight: 700;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  color: var(--blue);
  margin-bottom: 0.5rem;
}
.your-turn .your-turn-goal {
  font-size: 1.1rem;
  font-weight: 600;
  margin-bottom: 0.75rem;
}
.your-turn .your-turn-context {
  font-size: 0.95rem;
  color: var(--ink-secondary);
  margin-bottom: 1rem;
}

/* ── Recap ── */
.recap-section {
  border-top: 3px solid var(--ink);
  padding-top: 2.5rem;
  margin-top: 3rem;
}
.recap-section h2 {
  font-family: var(--mono);
  font-size: 1.25rem;
  font-weight: 700;
  margin-bottom: 1rem;
}
.recap-body { margin-bottom: 1.5rem; }
.recap-body p { margin-bottom: 0.75rem; }
.takeaways-list {
  list-style: none;
  padding: 0;
  margin-bottom: 1.5rem;
}
.takeaways-list li {
  padding: 0.5rem 0 0.5rem 1.5rem;
  position: relative;
  border-bottom: 1px solid var(--border-gray);
}
.takeaways-list li::before {
  content: "\2713";
  position: absolute;
  left: 0;
  color: var(--green);
  font-weight: 700;
}
.next-steps h3 {
  font-family: var(--mono);
  font-size: 0.7rem;
  font-weight: 700;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  color: var(--muted);
  margin-bottom: 0.5rem;
}
.next-steps ul {
  list-style: none;
  padding: 0;
}
.next-steps li {
  padding: 0.3rem 0 0.3rem 1.5rem;
  position: relative;
}
.next-steps li::before {
  content: "\2192";
  position: absolute;
  left: 0;
  color: var(--blue);
  font-weight: 700;
}

/* ── Sources ── */
.sources-section {
  margin-top: 2.5rem;
  padding-top: 1.5rem;
  border-top: 1px solid var(--border-gray);
}
.sources-section h3 {
  font-family: var(--mono);
  font-size: 0.7rem;
  font-weight: 700;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  color: var(--muted);
  margin-bottom: 0.75rem;
}
.sources-list {
  list-style: none;
  padding: 0;
}
.sources-list li {
  padding: 0.3rem 0;
}
.sources-list a {
  color: var(--blue);
  text-decoration: none;
  font-size: 0.9rem;
}
.sources-list a:hover { text-decoration: underline; }
.sources-list .source-name {
  font-family: var(--mono);
  font-size: 0.7rem;
  color: var(--muted);
  margin-left: 0.5rem;
}

/* ── Other articles ── */
.other-articles {
  margin-top: 2.5rem;
  padding-top: 1.5rem;
  border-top: 1px solid var(--border-gray);
}
.other-articles h3 {
  font-family: var(--mono);
  font-size: 0.7rem;
  font-weight: 700;
  letter-spacing: 0.1em;
  text-transform: uppercase;
  color: var(--muted);
  margin-bottom: 0.25rem;
}
.other-articles .oa-intro {
  font-size: 0.85rem;
  color: var(--muted);
  margin-bottom: 1rem;
}
.other-article-card {
  border: 1px solid var(--border-gray);
  padding: 1rem 1.25rem;
  margin-bottom: 0.5rem;
  display: flex;
  align-items: center;
  justify-content: space-between;
  gap: 1rem;
}
.other-article-card:hover {
  border-color: var(--ink);
}
.oa-info {
  flex: 1;
  min-width: 0;
}
.oa-title {
  font-weight: 600;
  font-size: 0.95rem;
  margin-bottom: 0.15rem;
}
.oa-meta {
  font-family: var(--mono);
  font-size: 0.65rem;
  color: var(--muted);
  letter-spacing: 0.04em;
}
.oa-votes {
  display: flex;
  gap: 0.4rem;
  flex-shrink: 0;
}
.oa-vote-btn {
  display: inline-flex;
  align-items: center;
  gap: 0.3rem;
  padding: 0.35rem 0.7rem;
  font-family: var(--mono);
  font-size: 0.65rem;
  font-weight: 700;
  letter-spacing: 0.04em;
  text-decoration: none;
  border: 1px solid var(--border-gray);
  color: var(--ink);
  background: var(--light-gray);
  transition: all 0.15s;
  white-space: nowrap;
}
.oa-vote-btn:hover {
  border-color: var(--ink);
  background: #fff;
}
.oa-vote-btn.vote-up:hover {
  border-color: var(--green);
  color: var(--green);
}
.oa-vote-btn.vote-down:hover {
  border-color: var(--red);
  color: var(--red);
}

/* ── Footer ── */
.session-footer {
  text-align: center;
  color: var(--muted);
  font-family: var(--mono);
  font-size: 0.6rem;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  margin-top: 3rem;
  padding: 1.5rem 0 2.5rem;
  border-top: 3px solid var(--ink);
}
.session-footer span { color: var(--ink); font-weight: 700; }

/* ── Responsive ── */
@media (max-width: 600px) {
  body { font-size: 16px; }
  .session-hero h1 { font-size: 1.5rem; }
  .step-number { width: 36px; height: 36px; font-size: 1rem; }
  .session-container { padding: 0 1rem 3rem; }
  .hero-meta { flex-wrap: wrap; gap: 0.75rem; }
}
</style>
</head>
<body>
  <div class="session-container">
    <a href="../index.html" class="back-link">&larr; Back to calendar</a>
    
    <div class="session-hero">
      <div class="hero-tag">Workshop</div>
      <h1>Your Context Window Is Leaking</h1>
      <div class="hero-subtitle">One Playwright snapshot costs 56KB. Twenty GitHub issues cost 59KB. After 30 minutes, 40% of your context is gone. Let&#x27;s fix that.</div>
      <div class="hero-meta">
        <span>30 min</span>
        <span> <span class="tag">MCP</span> <span class="tag">context-window</span> <span class="tag">claude-code</span> <span class="tag">developer-tools</span></span>
      </div>
    </div>
    <div class="context-block">
      <h2>What's happening</h2>
      <p>Here&#x27;s a pattern that&#x27;s been quietly killing long Claude Code sessions: <strong>MCP tool outputs are enormous</strong>.</p>

<p>MCP (Model Context Protocol) is how Claude Code talks to the outside world — GitHub, Playwright, your file system, databases. Every time a tool returns data, that raw response gets dumped straight into your context window. The 200K token limit sounds generous until you realize a single browser snapshot eats 56KB and a <code>gh issue list</code> burns 59KB.</p>

<p>A project called <strong>Context Mode</strong> just hit Hacker News with 174 points and a wild claim: they can compress MCP output by 98%. That means 315KB of raw tool output becomes 5.4KB. Sessions that used to slow down after 30 minutes now run for 3+ hours.</p>

<p>The trick? Instead of letting raw data flood your conversation, Context Mode routes tool outputs through <strong>isolated sandboxes</strong>. Your code processes the data, extracts what matters, and only the summary enters the context. Think of it like having an assistant who reads the entire report and hands you a sticky note with the three things that matter.</p>

<p>Today we&#x27;re going to install it, understand <em>why</em> it works (the mental model matters more than the config), and test it against real scenarios. Along the way, we&#x27;ll learn about FTS5 search, BM25 ranking, and how sandboxed execution actually keeps your context clean.</p>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">1</div>
        <h2>Understanding the Problem: Where Do Your Tokens Go?</h2>
      </div>
      <div class="step-body">
        <p>Before we install anything, let&#x27;s build intuition for <em>why</em> this problem exists.</p>

<p>Imagine your context window is a whiteboard in a meeting room. Every time someone references a document, they don&#x27;t just say &quot;see page 3&quot; — they photocopy the <em>entire document</em> and tape it to the whiteboard. After five references, you can&#x27;t see the whiteboard anymore.</p>

<p>That&#x27;s exactly what happens with MCP tools. When Claude Code calls <code>gh issue list</code>, GitHub doesn&#x27;t return a tidy summary. It returns every issue with full metadata — labels, assignees, timestamps, URLs, body text. All of it gets pasted into your conversation.</p>

<p>The key insight is that there are <strong>two directions</strong> of context consumption:</p>
<ol>
<li><strong>Tool definitions</strong> coming in (Cloudflare already solved this with Code Mode — 99.9% compression)</li>
<li><strong>Tool outputs</strong> coming back (this is what Context Mode tackles)</li>
</ol>

<p>With 81+ tools active, you can lose 72% of your context to definitions alone <em>before your first message</em>. Then every tool response chips away at what&#x27;s left.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Ask your agent to calculate how quickly a typical Claude Code session burns through context with common MCP tools
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>What&#x27;s the total context window size in tokens? (200K)</li><li>How would you convert KB to approximate token counts?</li><li>If someone runs 5 Playwright snapshots, 2 GitHub queries, and reads 3 log files in 30 minutes, what&#x27;s the total?</li><li>What percentage of the window is gone before any actual coding conversation?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should do some back-of-napkin math for you. Roughly: 1KB ≈ 250 tokens. So 56KB (Playwright) = ~14K tokens per snapshot. Five snapshots = 70K tokens. Two GitHub queries at 59KB each = ~30K tokens. Three log files at 45KB = ~34K tokens. That&#x27;s 134K tokens — <strong>67% of your entire context</strong> — consumed by raw tool output alone. Add the 143K for tool definitions and you&#x27;ve overflowed before writing a single line of code. The agent should present this as a simple breakdown table.</p></div>
      </details>
      </div>
        
        
      <div class="callout callout-tip">
        <div class="callout-label">Tip</div>
        A rough rule of thumb: 1KB of text ≈ 250 tokens. So a 56KB Playwright snapshot eats about 14,000 tokens. That&#x27;s the size of a solid conversation about architecture decisions — gone in one tool call.
      </div>
        
      <details class="reveal">
        <summary>Why can&#x27;t we just increase the context window?</summary>
        <div class="reveal-body"><p>Even if context windows keep growing (and they will), the problem scales too. More tools = more output. And there&#x27;s a subtler issue: <strong>attention degrades with length</strong>. A model with 200K tokens of context doesn&#x27;t attend equally to all of it. The more noise in your context, the worse the signal. Compression isn&#x27;t just about fitting more in — it&#x27;s about keeping the signal-to-noise ratio high so the model actually <em>uses</em> what&#x27;s there.</p></div>
      </details>
      </div>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">2</div>
        <h2>Install Context Mode and See What Changes</h2>
      </div>
      <div class="step-body">
        <p>Alright, let&#x27;s actually get this thing running. There are two install paths:</p>

<ol>
<li><strong>Plugin Marketplace</strong> — gives you auto-routing hooks plus slash commands (recommended)</li>
<li><strong>MCP-only</strong> — just the raw tools, no auto-routing</li>
</ol>

<p>We&#x27;re going with the Plugin Marketplace route because the auto-routing is the magic part. Without it, you&#x27;d have to manually pipe every tool output through the sandbox yourself.</p>

<p>The install is genuinely simple — but understanding <em>what it installs</em> is where the learning happens.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Ask your agent to walk you through installing Context Mode via the Claude Code Plugin Marketplace and explain what each piece does
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>What&#x27;s the difference between a plugin and a plain MCP server in Claude Code?</li><li>What&#x27;s a PreToolUse hook and why does Context Mode need one?</li><li>After installation, what should you see when you restart Claude Code?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should explain that you run <code>/install-plugin context-mode</code> (or add it to your MCP config manually). The key thing it installs is three tools — <code>execute</code> (run code in a sandbox), <code>index</code> (store content in a searchable knowledge base), and <code>search</code> (query that knowledge base). But the real magic is the <strong>PreToolUse hook</strong>: a callback that fires <em>before</em> any MCP tool returns its output, automatically routing that output through the sandbox instead of dumping it raw into context. After restarting Claude Code, you shouldn&#x27;t notice anything different in your workflow — that&#x27;s the point. The compression happens invisibly.</p></div>
      </details>
      </div>
        
        
      <div class="callout callout-warning">
        <div class="callout-label">Warning</div>
        You need to <strong>restart Claude Code</strong> after installation. The MCP server needs to register its tools and hooks fresh. If you skip the restart, the PreToolUse hook won&#x27;t be active and you&#x27;ll still get raw output.
      </div>
      <div class="callout callout-tip">
        <div class="callout-label">Tip</div>
        If you just want to experiment without committing, use the MCP-only install. You won&#x27;t get auto-routing, but you can manually test the <code>execute</code> and <code>search</code> tools to see how the sandbox works.
      </div>
        
      <details class="reveal">
        <summary>What exactly is a PreToolUse hook?</summary>
        <div class="reveal-body"><p>Think of it like middleware in a web server. When Express gets a request, it passes through middleware functions before hitting your route handler. A PreToolUse hook does the same thing for MCP tool calls — it intercepts the tool&#x27;s output <em>before</em> it enters the conversation context.</p>

<p>Context Mode&#x27;s hook says: &quot;Hey, before you paste that 56KB Playwright snapshot into the chat, let me run it through a sandbox first. I&#x27;ll extract what matters and give you a 299-byte summary instead.&quot;</p>

<p>The beauty is that Claude Code already supports this hook pattern — Context Mode just registers one that does the compression. You don&#x27;t change how you prompt or work. The hook fires automatically on every tool response.</p></div>
      </details>
      </div>
    </div>
    <div class="checkpoint">
      <div class="checkpoint-icon">&#10003;</div>
      <div>At this point you should have Context Mode installed and understand the two-part architecture: sandboxed execution for compression, and a PreToolUse hook for automatic routing. If you restarted Claude Code and see the `execute`, `index`, and `search` tools available, you&#x27;re good to go.</div>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">3</div>
        <h2>The Sandbox: How Raw Data Stays Out of Your Context</h2>
      </div>
      <div class="step-body">
        <p>This is the part that honestly confused me at first. How can you <em>process</em> data without it entering your context? Isn&#x27;t the whole point that the model needs to see the data to work with it?</p>

<p>Here&#x27;s the mental model that clicked for me: <strong>think of the sandbox like a kitchen, and your context window like the dining table.</strong></p>

<p>When you order food at a restaurant, the raw ingredients never come to your table. The chef works with them in the kitchen and delivers a finished plate. The sandbox works the same way:</p>

<ol>
<li>A tool returns raw data (the ingredients)</li>
<li>The sandbox runs your processing script (the chef cooks)</li>
<li>Only <code>stdout</code> — what the script explicitly prints — enters the conversation (the plated dish)</li>
</ol>

<p>The raw data literally never leaves the subprocess. It&#x27;s allocated in a separate process&#x27;s memory, processed there, and discarded. Only the <code>console.log()</code> or <code>print()</code> output crosses the boundary.</p>

<p>Ten language runtimes are supported (JS, TS, Python, Shell, Ruby, Go, Rust, PHP, Perl, R), and it auto-detects Bun for 3-5x faster JavaScript execution.</p>

<p>The credential passthrough is clever too — if you&#x27;re authenticated with <code>gh</code> or <code>aws</code> CLI, the sandbox inherits those credentials through environment variables. So you can run <code>gh issue list</code> inside the sandbox, process the JSON there, and only print the three fields you care about.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Ask your agent to explain how Context Mode would handle a specific scenario: you ask Claude Code to review the last 20 GitHub issues for a repository. Walk through the data flow step by step.
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>What does the raw `gh issue list` output look like? (Hint: full JSON with every field)</li><li>Where does the processing happen — in the model&#x27;s context or somewhere else?</li><li>What&#x27;s the difference between what the sandbox *sees* and what the conversation *sees*?</li><li>How do authenticated CLI tools work inside the sandbox?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should trace the full flow: (1) Claude decides to check GitHub issues, (2) instead of running <code>gh issue list</code> directly (which would dump ~59KB of JSON), the PreToolUse hook intercepts and routes through <code>execute</code>, (3) the sandbox spawns a subprocess that runs <code>gh issue list --json number,title,state,labels</code> — credentials pass through automatically, (4) the script processes the JSON <em>inside the subprocess</em>, maybe grouping by label or filtering by state, (5) only the <code>console.log()</code> output enters the conversation — something like a 1.1KB summary with issue numbers, titles, and a count by category. The 59KB of raw GitHub JSON never touches the context window.</p></div>
      </details>
      </div>
        
        
      <div class="callout callout-tip">
        <div class="callout-label">Tip</div>
        The sandbox isolation is per-call. Scripts from different <code>execute</code> calls can&#x27;t access each other&#x27;s memory or state. This is a security feature — if one script processes sensitive API responses, another script can&#x27;t peek at them.
      </div>
        
      <details class="reveal">
        <summary>How is this different from just asking Claude to summarize the output?</summary>
        <div class="reveal-body"><p>Great question, and it gets at a fundamental distinction. When Claude summarizes, the raw data <strong>has already entered the context window</strong>. The tokens are spent. Even if Claude writes a tidy summary in its response, the full 59KB of GitHub JSON is sitting in the conversation history, consuming tokens for the rest of the session.</p>

<p>With the sandbox approach, the raw data is never serialized into the conversation at all. It exists in subprocess memory, gets processed there, and only the output crosses the boundary. It&#x27;s the difference between reading a 500-page book and writing a summary (you still read all 500 pages) versus having someone else read it and tell you the key points (you only heard the summary).</p>

<p>This is why the compression is so dramatic — it&#x27;s not summarization, it&#x27;s <strong>data routing</strong>.</p></div>
      </details>
      </div>
    </div>
    <div class="decision-point">
      <h3>Quick Check</h3>
      <div class="question">You&#x27;re debugging a failing test suite that produces 85KB of output. Which approach keeps your context window cleanest?</div>
      
        <div class="decision-option">
          <input type="radio" name="decision_6" id="decision_6_opt0">
          <label for="decision_6_opt0">Route the test output through Context Mode&#x27;s sandbox, extract only failing test names and error messages</label>
          <div class="decision-feedback correct">&#10003; Correct! The sandbox processes the full 85KB of test output in an isolated subprocess. Your script filters for failures, extracts test names and error messages, and prints maybe 200 bytes. The raw output never enters the conversation — you get the signal without the noise.</div>
        </div>
        <div class="decision-option">
          <input type="radio" name="decision_6" id="decision_6_opt1">
          <label for="decision_6_opt1">Run the tests normally and ask Claude to focus only on the failures</label>
          <div class="decision-feedback incorrect">&#10007; Not quite. Even if Claude only *discusses* the failures, the full 85KB of test output is already in your context window. Those tokens are spent permanently for the rest of the session. Asking the model to &#x27;focus&#x27; doesn&#x27;t reclaim the tokens — they&#x27;re already consumed.</div>
        </div>
        <div class="decision-option">
          <input type="radio" name="decision_6" id="decision_6_opt2">
          <label for="decision_6_opt2">Run the tests and pipe through `grep FAIL` before giving to Claude</label>
          <div class="decision-feedback incorrect">&#10007; Not quite. This is actually a reasonable workaround! Piping through grep does reduce the output before it hits the context. But Context Mode&#x27;s sandbox is more flexible — you can write richer processing logic (group by test file, extract stack traces, count by category) and it handles credential passthrough for authenticated tools too. The sandbox approach generalizes better.</div>
        </div>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">4</div>
        <h2>The Knowledge Base: FTS5, BM25, and Why Search Beats Stuffing</h2>
      </div>
      <div class="step-body">
        <p>The sandbox handles real-time compression. But what about information you need to <em>come back to</em> during a long session? That&#x27;s where the knowledge base comes in.</p>

<p>Context Mode includes <code>index</code> and <code>search</code> tools backed by <strong>SQLite FTS5</strong> — Full-Text Search 5. Here&#x27;s the analogy that helped me: imagine you&#x27;re researching a topic and you have two strategies.</p>

<p><strong>Strategy 1: Pile everything on your desk.</strong> Print every article, every doc page, every API reference. Stack them up. When you need something, dig through the pile. This is what happens when raw tool output fills your context.</p>

<p><strong>Strategy 2: Build an index.</strong> Read each source, break it into sections, file them by topic with sticky tabs. When you need something, look it up. You only pull out the specific section you need. This is what FTS5 does.</p>

<p>The <code>index</code> tool breaks markdown content into chunks by headings (keeping code blocks intact — crucial detail), then stores them in an FTS5 virtual table. When you <code>search</code>, it uses <strong>BM25 ranking</strong> to find the most relevant chunks.</p>

<p>BM25 is worth understanding because it shows up everywhere in search. It&#x27;s basically asking three questions:</p>
<ul>
<li><strong>How often does this term appear in this document?</strong> (term frequency)</li>
<li><strong>How rare is this term across all documents?</strong> (inverse document frequency — rare terms matter more)</li>
<li><strong>How long is this document?</strong> (normalization — a term in a short doc is more significant than in a long one)</li>
</ul>

<p>The <code>fetch_and_index</code> tool extends this to URLs — it fetches a web page, converts HTML to markdown, chunks it, and indexes it. The raw page <em>never enters context</em>. You search it later and get back only the relevant chunks.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Ask your agent to explain how you&#x27;d use Context Mode&#x27;s knowledge base to research a new library&#x27;s API without burning context tokens
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>If you need to reference API docs multiple times during a session, what&#x27;s the cost of fetching them each time?</li><li>What does &#x27;chunking by headings&#x27; mean in practice for API documentation?</li><li>How does BM25 decide which chunk to return when you search for &#x27;authentication&#x27;?</li><li>What&#x27;s the advantage of Porter stemming when searching technical docs?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should walk through the workflow: (1) use <code>fetch_and_index</code> with the library&#x27;s docs URL — the HTML gets fetched, converted to markdown, and chunked by headings into the SQLite FTS5 table, (2) the raw docs (potentially hundreds of KB) never enter context, (3) later when you need the authentication section, you call <code>search</code> with &#x27;authentication&#x27; — BM25 ranks chunks by relevance and returns the exact section with its heading hierarchy, (4) Porter stemming means searching &#x27;authenticate&#x27; also matches &#x27;authentication&#x27;, &#x27;authenticated&#x27;, etc. The agent should emphasize that you can search the same indexed content repeatedly throughout a 3-hour session without any additional context cost.</p></div>
      </details>
      </div>
        
        
        
      <details class="reveal">
        <summary>BM25 vs. vector embeddings — when would you use which?</summary>
        <div class="reveal-body"><p>BM25 is a keyword-based algorithm. It excels when you know the specific terms you&#x27;re looking for — function names, error codes, config keys. It&#x27;s fast, deterministic, and doesn&#x27;t require an embedding model.</p>

<p>Vector embeddings (what you&#x27;d use with a vector database like Pinecone or Chroma) capture <em>semantic</em> similarity. Searching &#x27;how to log in&#x27; would match content about &#x27;authentication flow&#x27; even though they share no keywords.</p>

<p>For code and API documentation, BM25 is often the better choice. You&#x27;re usually searching for specific terms — <code>useEffect</code>, <code>CORS</code>, <code>401 error</code>. The terms are precise and technical. BM25 handles this beautifully and runs locally in SQLite without needing an API call to an embedding service.</p>

<p>Context Mode chose wisely here — for the use case of indexed technical docs and code output, BM25 is fast, free, and accurate.</p></div>
      </details>
      </div>
    </div>
    <div class="step-section">
      <div class="step-header">
        <div class="step-number">5</div>
        <h2>Real-World Test: The 315KB → 5.4KB Session</h2>
      </div>
      <div class="step-body">
        <p>Let&#x27;s see how all these pieces work together in a real scenario. The Context Mode team validated across 11 real-world workflows. Here are the numbers that jumped out at me:</p>

<p>| Scenario | Raw Size | Compressed | Reduction |</p>
<p>|----------|----------|------------|----------|</p>
<p>| Playwright snapshot | 56 KB | 299 B | 99.5% |</p>
<p>| 20 GitHub issues | 59 KB | 1.1 KB | 98.1% |</p>
<p>| 500-line access log | 45 KB | 155 B | 99.7% |</p>
<p>| 500-row CSV analytics | 85 KB | 222 B | 99.7% |</p>
<p>| 153 git commits | 11.6 KB | 107 B | 99.1% |</p>

<p>The cumulative effect is what matters most: over a full session, 315KB of raw output becomes 5.4KB. Context remaining after 45 minutes: <strong>99%</strong> instead of 60%.</p>

<p>But here&#x27;s the thing that really sold me — it&#x27;s not just about fitting more in. When your context is 60% full of raw JSON and log files, the model&#x27;s attention is diluted. It&#x27;s trying to reason about your code while wading through thousands of lines of GitHub metadata. Compression isn&#x27;t just a space optimization — it&#x27;s an <strong>attention optimization</strong>.</p>
        
      <div class="agent-interaction">
        <div class="agent-goal">
          <div class="agent-goal-label">Ask your agent</div>
          Ask your agent to design a test you could run yourself: a Claude Code session that would normally burn through context in 30 minutes, then re-run it with Context Mode to measure the difference
        </div>
        
        <div class="agent-hints">
          <div class="agent-hints-label">Think about it</div>
          <ul><li>What combination of tool calls would consume the most context in a typical dev session?</li><li>How would you measure &#x27;context remaining&#x27; before and after?</li><li>What&#x27;s a realistic 30-minute workflow — debugging? Code review? Feature research?</li><li>How would you make the comparison fair (same tasks, same prompts)?</li></ul>
        </div>
        
      <details class="reveal">
        <summary>What the agent gives back</summary>
        <div class="reveal-body"><p>The agent should design a reproducible test workflow — something like: (1) Open a medium-sized repo, (2) run <code>gh issue list</code> for the last 20 issues, (3) take 3 Playwright snapshots of the project&#x27;s web UI, (4) read two log files, (5) run the test suite and review failures, (6) do a git log for the last 100 commits. It should suggest measuring context usage by noting when Claude starts &#x27;forgetting&#x27; earlier conversation or when you get a context limit warning. The agent should estimate the raw session would hit ~250KB of tool output (game over in 25 minutes) while Context Mode would keep it under 4KB (barely a dent after 3 hours).</p></div>
      </details>
      </div>
        
        
      <div class="callout callout-tip">
        <div class="callout-label">Tip</div>
        The &#x27;repo research&#x27; scenario is the most dramatic: 986KB → 62KB across a multi-agent subagent flow. That&#x27;s because subagents learn to use <code>batch_execute</code> as their primary tool, compressing across multiple calls at once.
      </div>
        
      <details class="reveal">
        <summary>What about the subagent upgrade?</summary>
        <div class="reveal-body"><p>One subtle but powerful detail: Context Mode automatically upgrades Bash subagents to <code>general-purpose</code> subagents so they can access MCP tools. This matters because in default Claude Code, when a subagent is spawned to handle a subtask (like &#x27;go research this library&#x27;), it often uses raw Bash commands — <code>curl</code>, <code>gh</code>, <code>cat</code> — and all that output flows straight into context.</p>

<p>With Context Mode, those subagents get access to the <code>execute</code> and <code>batch_execute</code> tools instead. The repo research scenario dropped from 37 tool calls to just 5, and from 986KB to 62KB. The subagent does the same work but routes everything through sandboxes automatically.</p>

<p>This is the compounding effect of the PreToolUse hook — it doesn&#x27;t just compress your direct tool calls, it compresses everything your subagents do too.</p></div>
      </details>
      </div>
    </div>
    <div class="checkpoint">
      <div class="checkpoint-icon">&#10003;</div>
      <div>You should now understand all three pillars: sandbox execution (the kitchen metaphor — raw data stays in the subprocess), the FTS5 knowledge base (index once, search many times without re-fetching), and the PreToolUse hook (automatic routing so you don&#x27;t change your workflow). The numbers should feel intuitive — of course a 56KB DOM snapshot can be reduced to 299 bytes if you only extract the text content you care about.</div>
    </div>
    <div class="your-turn">
      <h3>Your Turn</h3>
      <div class="your-turn-goal">Design a prompt that asks your AI agent to create a Context Mode workflow for a specific use case: triaging a production incident using logs, metrics, and GitHub issues</div>
      <div class="your-turn-context">Imagine it&#x27;s 2 AM and your production service is throwing 500 errors. You need to pull access logs (45KB+), check recent deployments via git log, scan open GitHub issues for related reports, and maybe fetch your monitoring dashboard. Without Context Mode, this investigation alone would consume your entire context window. With it, you can keep investigating for hours.</div>
      
      <div class="agent-hints">
        <div class="agent-hints-label">Think about it</div>
        <ul><li>What data sources does an incident investigation typically involve?</li><li>For each source, what&#x27;s the &#x27;signal&#x27; vs. the &#x27;noise&#x27;? What would you actually print from the sandbox?</li><li>How might you use the knowledge base to index runbook documentation *before* incidents happen?</li><li>What&#x27;s the order of operations — what do you check first, and how does each finding inform the next step?</li></ul>
      </div>
      
      <details class="reveal">
        <summary>See a sample prompt</summary>
        <div class="reveal-body">
          <div class="code-block">
            <span class="code-caption">One way you could prompt it</span>
            <button class="copy-btn">COPY</button>
            <pre><code>I need a Context Mode workflow for production incident triage. Here&#x27;s the scenario: I&#x27;m investigating 500 errors on a web service. Walk me through how to use Context Mode&#x27;s execute and index tools to investigate without burning context. Specifically: (1) How to process access logs in the sandbox to extract only error requests, group by endpoint, and show the error timeline, (2) How to check git log for recent deploys and correlate timestamps with when errors started, (3) How to scan GitHub issues for related reports from users, (4) How to pre-index our runbook documentation so I can search it during the incident. For each step, explain what the sandbox script would extract vs. what the raw output would have been, and estimate the context savings.</code></pre>
          </div>
        </div>
      </details>
    </div>
    <div class="decision-point">
      <h3>Quick Check</h3>
      <div class="question">You need to reference the same API documentation 5 times during a session. What&#x27;s the most context-efficient approach?</div>
      
        <div class="decision-option">
          <input type="radio" name="decision_11" id="decision_11_opt0">
          <label for="decision_11_opt0">Use fetch_and_index once, then search 5 times</label>
          <div class="decision-feedback correct">&#10003; Correct! Indexing costs almost nothing — the raw docs are fetched and chunked in the sandbox, never entering context. Each search returns only the relevant chunk (a few hundred bytes). Five searches might cost 2KB total. Fetching the same page 5 times through raw MCP would cost 5x the full page size.</div>
        </div>
        <div class="decision-option">
          <input type="radio" name="decision_11" id="decision_11_opt1">
          <label for="decision_11_opt1">Fetch the docs once and ask Claude to remember them</label>
          <div class="decision-feedback incorrect">&#10007; Not quite. The full docs still enter context on that first fetch — say 80KB. Even if Claude &#x27;remembers&#x27; them, those 80KB of tokens are permanently consumed. And as the session goes on, the model&#x27;s attention to those docs degrades as newer content pushes them further back in context.</div>
        </div>
        <div class="decision-option">
          <input type="radio" name="decision_11" id="decision_11_opt2">
          <label for="decision_11_opt2">Use execute to fetch and summarize the docs each time you need them</label>
          <div class="decision-feedback incorrect">&#10007; Not quite. This works but is inefficient. Each execute call re-fetches and re-processes the docs. The knowledge base exists precisely to avoid this — index once, search many times. Plus, BM25 search returns the exact relevant section, while a sandbox summary might miss the specific detail you need.</div>
        </div>
    </div>
    <div class="recap-section">
      <h2>Recap</h2>
      <div class="recap-body"><p>Let&#x27;s zoom out. We started with a concrete problem — MCP tools are flooding context windows with raw data, making long Claude Code sessions impossible. We learned that Context Mode solves this with three interlocking pieces:</p>

<p><strong>The Sandbox</strong> processes raw data in isolated subprocesses. Only stdout crosses back into context. Think kitchen → dining table: ingredients stay in the kitchen, you only see the plated dish.</p>

<p><strong>The Knowledge Base</strong> (SQLite FTS5 + BM25) lets you index large documents once and search them repeatedly with zero additional context cost. It&#x27;s your personal search engine that lives alongside your session.</p>

<p><strong>The PreToolUse Hook</strong> makes all of this automatic. You don&#x27;t change how you prompt or work — the hook intercepts tool outputs and routes them through compression before they can bloat your context.</p>

<p>The result: 315KB → 5.4KB. Sessions that last 3+ hours instead of 30 minutes. And arguably better results, because the model&#x27;s attention isn&#x27;t diluted by thousands of lines of raw JSON.</p>

<p>The bigger lesson here isn&#x27;t about one tool — it&#x27;s about a design pattern. <strong>Every time raw data enters an LLM context, ask: does the model need ALL of this, or just the insight extracted from it?</strong> That question will keep being relevant as context windows grow and tool ecosystems expand.</p></div>
      <ul class="takeaways-list"><li>MCP tool outputs are the hidden context killer — a single Playwright snapshot eats 56KB (14K tokens), and it adds up fast across a real session</li><li>Sandbox isolation means raw data never enters the conversation — processing happens in a subprocess, only stdout crosses the boundary</li><li>FTS5 + BM25 gives you a persistent, searchable knowledge base with zero context cost — index once, search all session</li><li>The PreToolUse hook makes compression invisible — you don&#x27;t change your workflow, the routing happens automatically</li><li>Context compression isn&#x27;t just about space — it&#x27;s about attention quality. Less noise means the model reasons better about the signal</li></ul>
      
      <div class="next-steps">
        <h3>Where to go next</h3>
        <ul><li>Install Context Mode and run your normal workflow for a day — notice where you used to hit context limits and whether those limits disappear</li><li>Experiment with the knowledge base: index your project&#x27;s docs, your team&#x27;s runbooks, or a library&#x27;s API reference and search them throughout a session</li><li>Build a mental checklist: before any long Claude Code session, think about which data sources will generate the most raw output and how you&#x27;d want them compressed</li><li>Explore the batch_execute tool for multi-step subagent workflows where the compression compounds across many tool calls</li></ul>
      </div>
    </div>
    <div class="sources-section">
      <h3>Sources</h3>
      <ul class="sources-list"><li><a href="https://mksg.lu/blog/context-mode" target="_blank" rel="noopener">Stop Burning Your Context Window – How We Cut MCP Output by 98% in Claude Code</a> <span class="source-name">(Hacker News AI)</span></li></ul>
    </div>
    <div class="other-articles">
      <h3>What else was in the news</h3>
      <p class="oa-intro">These articles were also available today. Vote to help shape future sessions.</p>
      
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">VectifyAI/PageIndex</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%20VectifyAI/PageIndex&body=vote%3Aup%0Atags%3Aagents%2Ctools%2Crag%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%20VectifyAI/PageIndex&body=vote%3Adown%0Atags%3Aagents%2Ctools%2Crag%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">datawhalechina/hello-agents</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%20datawhalechina/hello-agents&body=vote%3Aup%0Atags%3Aagents%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%20datawhalechina/hello-agents&body=vote%3Adown%0Atags%3Aagents%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">ruvnet/wifi-densepose</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%20ruvnet/wifi-densepose&body=vote%3Aup%0Atags%3Atools%2Crag%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%20ruvnet/wifi-densepose&body=vote%3Adown%0Atags%3Atools%2Crag%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">4thfever/cultivation-world-simulator</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%204thfever/cultivation-world-simulator&body=vote%3Aup%0Atags%3Aagents%2Copen-source%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%204thfever/cultivation-world-simulator&body=vote%3Adown%0Atags%3Aagents%2Copen-source%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">muratcankoylan/Agent-Skills-for-Context-Engineering</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%20muratcankoylan/Agent-Skills-for-Context-Engineering&body=vote%3Aup%0Atags%3Aagents%2Ctools%2Ctechnique%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%20muratcankoylan/Agent-Skills-for-Context-Engineering&body=vote%3Adown%0Atags%3Aagents%2Ctools%2Ctechnique%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">anthropics/skills</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%20anthropics/skills&body=vote%3Aup%0Atags%3Aagents%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%20anthropics/skills&body=vote%3Adown%0Atags%3Aagents%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">QwenLM/Qwen-Agent</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%20QwenLM/Qwen-Agent&body=vote%3Aup%0Atags%3Aagents%2Copen-source%2Ctools%2Ccoding%2Crag%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%20QwenLM/Qwen-Agent&body=vote%3Adown%0Atags%3Aagents%2Copen-source%2Ctools%2Ccoding%2Crag%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">NevaMind-AI/memU</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%20NevaMind-AI/memU&body=vote%3Aup%0Atags%3Aagents%2Ctools%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%20NevaMind-AI/memU&body=vote%3Adown%0Atags%3Aagents%2Ctools%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">modelscope/ms-swift</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%20modelscope/ms-swift&body=vote%3Aup%0Atags%3Atools%2Cfine-tuning%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%20modelscope/ms-swift&body=vote%3Adown%0Atags%3Atools%2Cfine-tuning%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
        <div class="other-article-card">
          <div class="oa-info">
            <div class="oa-title">agentscope-ai/agentscope</div>
            <div class="oa-meta">GitHub Trending Python</div>
          </div>
          <div class="oa-votes">
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8D%20agentscope-ai/agentscope&body=vote%3Aup%0Atags%3Aagents%2Ctools%2Ctechnique%2Caudio%2Crag%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-up">&#x1F44D; More like this</a>
            <a href="https://github.com/coldbrewnosugar/ai-course/issues/new?labels=vote&title=%F0%9F%91%8E%20agentscope-ai/agentscope&body=vote%3Adown%0Atags%3Aagents%2Ctools%2Ctechnique%2Caudio%2Crag%0Asource%3AGitHub%20Trending%20Python%0Adate%3A2026-02-28%0Atrack%3Ageneral" target="_blank" rel="noopener" class="oa-vote-btn vote-down">&#x1F44E; Not interested</a>
          </div>
        </div>
    </div>
    <footer class="session-footer">
      <span>Tinker</span> &middot; Build with AI, daily
    </footer>
  </div>
  <script>
document.addEventListener('DOMContentLoaded', function() {
  // Copy-to-clipboard
  document.querySelectorAll('.copy-btn').forEach(function(btn) {
    btn.addEventListener('click', function() {
      var code = btn.closest('.code-block').querySelector('code').textContent;
      navigator.clipboard.writeText(code).then(function() {
        btn.textContent = 'COPIED';
        btn.classList.add('copied');
        setTimeout(function() {
          btn.textContent = 'COPY';
          btn.classList.remove('copied');
        }, 2000);
      });
    });
  });
});
</script>
</body>
</html>